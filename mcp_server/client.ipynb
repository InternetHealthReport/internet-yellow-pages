{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49823a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell runs only once per kernel restart.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"_executed_once\" not in get_ipython().user_ns:\n",
    "    print(\"This cell runs only once per kernel restart.\")\n",
    "    get_ipython().user_ns[\"_executed_once\"] = True\n",
    "\n",
    "    import nest_asyncio\n",
    "\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda58b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/justin-loye/iyp-mcp\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/justin-loye/iyp-mcp</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=324961;https://logfire-us.pydantic.dev/justin-loye/iyp-mcp\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/justin-loye/iyp-mcp\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:49:02.272 agent run\n",
      "07:49:02.333   chat gpt-oss:120b-cloud\n",
      "07:49:03.788   running 1 tool\n",
      "07:49:03.788     running tool: list_iyp_datasets\n",
      "07:49:03.857   chat gpt-oss:120b-cloud\n",
      "07:49:08.655   running 1 tool\n",
      "07:49:08.655     running tool: get_resource\n",
      "07:49:08.668   chat gpt-oss:120b-cloud\n",
      "**Dataset:** **Tranco – “Tranco list”** (`tranco.top1m`)\n",
      "\n",
      "**Description (from the IYP documentation)**  \n",
      "\n",
      "> The Tranco list is a research‑oriented top‑sites ranking hardened against manipulation. It **combines the rankings of several source lists** to produce a daily list that is based on data of the past 30 days.  \n",
      "> IYP uses this data to create and annotate `DomainName` nodes.\n",
      "\n",
      "**Key points**\n",
      "\n",
      "- **Purpose:** Provides a stable, manipulation‑resistant ranking of the most popular web sites.  \n",
      "- **Source:** Aggregates multiple existing ranking sources (see the Tranco methodology at https://tranco-list.eu/methodology).  \n",
      "- **Coverage:** Daily list of the top 1 million domains, reflecting the last 30 days of activity.  \n",
      "- **IYP usage:** Each domain is represented as a `DomainName` node; its rank is stored on a `RANK` relationship to a `Ranking` node (e.g., `(:DomainName {name:\"google.com\"})-[:RANK {rank:1}]->(:Ranking {name:\"Tranco top 1M\"})`).  \n",
      "- **Dependencies:** This crawler operates independently; it does not rely on other IYP crawlers.\n",
      "\n",
      "**Reference**  \n",
      "- **URL:** https://tranco-list.eu  \n",
      "- **Read‑me / documentation:** https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme  \n",
      "\n",
      "This is the most comprehensive description available for the Tranco website‑ranking dataset within the Internet Yellow Pages.\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "import logfire\n",
    "\n",
    "logfire.configure()\n",
    "logfire.instrument_pydantic_ai()\n",
    "\n",
    "\n",
    "# ollama_model = OpenAIChatModel(\n",
    "#     model_name=\"qwen3:8b\",\n",
    "#     provider=OllamaProvider(base_url=\"http://localhost:11434/v1\"),\n",
    "# )\n",
    "\n",
    "ollama_model = OpenAIChatModel(\n",
    "    model_name=\"gpt-oss:120b-cloud\",\n",
    "    provider=OllamaProvider(base_url=\"https://ollama.com/v1\",\n",
    "                            api_key=os.getenv(\"OLLAMA_API_KEY\")),\n",
    ")\n",
    "\n",
    "doc_server = MCPServerStreamableHTTP(\"http://localhost:8002/mcp\")\n",
    "neo4j_server = MCPServerStreamableHTTP(\"http://localhost:8001/api/mcp\")\n",
    "system_prompt= \"\"\"You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet).\n",
    "Use available tools to query the database or retrieve informations about the databse documentation. Query IYP cypher query if needed to reply to the user. If the user's request cannot be answered by IYP, simply say that you don't know\"\"\"\n",
    "agent = Agent(\n",
    "    ollama_model, toolsets=[doc_server, neo4j_server], system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "# result = agent.run_sync(\n",
    "#     \"Give me the best description of the dataset related to tranco website ranking\"\n",
    "# )\n",
    "\n",
    "result = agent.run_sync(\n",
    "    \"Give me the best description of the dataset related to tranco website ranking\"\n",
    ")\n",
    "print(result.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4328de7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content=\"You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet).\\nUse available tools to query the database or retrieve informations about the databse documentation. Query IYP cypher query if needed to reply to the user. If the user's request cannot be answered by IYP, simply say that you don't know\", timestamp=datetime.datetime(2025, 11, 27, 7, 49, 2, 325287, tzinfo=datetime.timezone.utc)), UserPromptPart(content='Give me the best description of the dataset related to tranco website ranking', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 2, 325292, tzinfo=datetime.timezone.utc))], run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd'),\n",
       " ModelResponse(parts=[ThinkingPart(content='We need to give best description of the dataset related to tranco website ranking. Use IYP dataset info. Need to list datasets then get resource for the dataset. So first list datasets to find name matching tranco. Use list_iyp_datasets.', id='reasoning', provider_name='ollama'), ToolCallPart(tool_name='list_iyp_datasets', args='{}', tool_call_id='call_zyt5h9wu')], usage=RequestUsage(input_tokens=615, output_tokens=74), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 3, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-613', finish_reason='tool_call', run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='list_iyp_datasets', content=[{'organization': 'Alice-LG', 'name': 'IXP route server looking glass snapshots', 'url': 'https://github.com/alice-lg/alice-lg', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': None, 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'AMS-IX', 'url': 'https://lg.ams-ix.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.amsix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'BCIX', 'url': 'https://lg.bcix.de', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.bcix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'DE-CIX', 'url': 'https://lg.de-cix.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.decix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'IX.br', 'url': 'https://lg.ix.br', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.ixbr', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'LINX', 'url': 'https://alice-rs.linx.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.linx', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'Megaport', 'url': 'https://lg.megaport.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.megaport', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'Netnod', 'url': 'https://lg.netnod.se', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.netnod', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'APNIC', 'name': 'AS population estimate', 'url': 'https://stats.labs.apnic.net/aspop', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/apnic#readme', 'reference_name': 'apnic.eyeball', 'readme_header': '# APNIC population estimates -- https://labs.apnic.net/\\n\\nPopulation per AS estimated using an advertisement on Youtube. This dataset \\nprovides:\\n- the percentage of the population per country/AS\\n- AS ranking in terms of population\\n- AS names\\n\\n'}, {'organization': 'BGPKIT', 'name': 'as2rel', 'url': 'https://data.bgpkit.com/as2rel', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.as2rel_v4', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'BGPKIT', 'name': 'as2rel', 'url': 'https://data.bgpkit.com/as2rel', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.as2rel_v6', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'BGPKIT', 'name': 'peer-stats', 'url': 'https://data.bgpkit.com/peer-stats', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.peerstats', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'BGPKIT', 'name': 'pfx2as', 'url': 'https://data.bgpkit.com/pfx2as', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.pfx2asn', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'bgp.tools', 'name': 'Anycast prefix tags', 'url': 'https://github.com/bgptools/anycast-prefixes', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.anycast_prefixes', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'bgp.tools', 'name': 'AS names', 'url': 'https://bgp.tools/kb/api', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.as_names', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'bgp.tools', 'name': 'AS tags', 'url': 'https://bgp.tools/kb/api', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.tags', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'CAIDA', 'name': 'AS to Organizations', 'url': 'https://catalog.caida.org/dataset/as_organizations', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.as2org', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'AS Rank', 'url': 'https://doi.org/10.21986/CAIDA.DATA.AS-RANK', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.asrank', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'AS Relationships', 'url': 'https://catalog.caida.org/dataset/as_relationships_serial_1', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.as_relationships_v4', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'AS Relationships', 'url': 'https://catalog.caida.org/dataset/as_relationships_serial_1', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.as_relationships_v6', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'IXPs Dataset', 'url': 'https://doi.org/10.21986/CAIDA.DATA.IXPS', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.ixs', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'IXPs Dataset', 'url': 'https://doi.org/10.21986/CAIDA.DATA.IXPS', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.ix_asns', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'Cisco', 'name': 'Umbrella Popularity List', 'url': 'https://s3-us-west-1.amazonaws.com/umbrella-static/index.html', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco#readme', 'reference_name': 'cisco.umbrella_top1m', 'readme_header': '# Cisco Umbrella -- https://umbrella-static.s3-us-west-1.amazonaws.com/index.html\\n\\nThe popularity list contains most queried domains (ranging from TLDs to FQDNs)\\nbased on passive DNS usage across the Umbrella global network.\\n\\nIYP uses this data to create and annotate DomainName and HostName nodes.\\n'}, {'organization': 'Citizen Lab', 'name': 'URL testing lists', 'url': 'https://github.com/citizenlab/test-lists', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/citizenlab#readme', 'reference_name': 'citizenlab.urldb', 'readme_header': \"# Citizen Lab -- https://github.com/citizenlab/test-lists/blob/master/lists/\\n\\nCitizen lab's test lists are URL testing lists intended to help in testing URL censorship, divided by country codes. In addition to these local lists, the global list consists of a wide range of internationally relevant and popular websites, including sites with content that is perceived to be provocative or objectionable. The dataset tha maps URL to Category.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/datasets', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.ranking_bucket', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/dns/top/ases', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.dns_top_ases', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/dns/top/locations', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.dns_top_locations', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/ranking/top (top 100 domain names)', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.top100', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Emile Aben', 'name': 'AS names', 'url': 'https://github.com/emileaben/asnames', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/emileaben#readme', 'reference_name': 'emileaben.as_names', 'readme_header': \"# EmileAben's AS Names -- https://github.com/emileaben/asnames\\n\\nData collected by EmileAben's AS Names, including:\\n\\n- AS numbers\\n- AS names\\n\"}, {'organization': 'Google', 'name': 'CrUX top 1M websites per country', 'url': 'https://developer.chrome.com/docs/crux', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/google#readme', 'reference_name': 'google.crux_top1m_country', 'readme_header': \"# Google CrUX -- https://developer.chrome.com/docs/crux\\n\\nThe Chrome User Experience Report (CrUX for short) is a dataset collected by\\nGoogle that reflects how real-world Chrome users experience popular\\ndestinations on the web.\\n\\nCrUX data is collected from real browsers around the world, based on certain\\nbrowser options which determine user eligibility. A set of dimensions and metrics\\nare collected which allow site owners to determine how users experience their sites.\\n\\nIYP fetches CrUX's [top 1M popular websites per country](https://github.com/InternetHealthReport/crux-top-lists-country).\\nUnlike others, CrUX rankings are bucketed by rank magnitude order, not by\\nspecific rank. For example, ranks are 1000, 10k, 100k, or 1M.\\n\\nIn addition, CrUX ranks *origins* (e.g., https://www.google.com), not domain\\nor host names. In IYP we extract the hostname part of the origin and model this\\ndataset using the hostname.\\n\"}, {'organization': 'IHR', 'name': 'AS Hegemony', 'url': 'https://www.ihr.live/en/documentation#AS-dependency', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.local_hegemony_v4', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'IHR', 'name': 'AS Hegemony', 'url': 'https://www.ihr.live/en/documentation#AS-dependency', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.local_hegemony_v6', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'IHR', 'name': 'Country Dependency', 'url': 'https://www.ihr.live/en/documentation#Country-s-network-dependency', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.country_dependency', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'IHR', 'name': 'ROV', 'url': 'https://www.ihr.live/en/documentation#Route-Origin-Validation', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.rov', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'Internet Intelligence Lab', 'name': 'AS to Organization Mapping', 'url': 'https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/inetintel#readme', 'reference_name': 'inetintel.as_org', 'readme_header': '# Internet Intelligence Lab - Dataset: AS to Organization mapping -- https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\\n\\nThe dataset contains historical and current versions of the AS to Organization \\nmapping datasets. A mapping will be created between AS to its sibling ASes.\\n'}, {'organization': 'IPinfo', 'name': 'IP to Country Mapping', 'url': 'https://ipinfo.io', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ipinfo#readme', 'reference_name': 'ipinfo.ip_country', 'readme_header': '# IPinfo -- https://ipinfo.io/\\n\\nIPinfo is an IP geolocation service, that provides different kinds of IP databases,\\nincluding a [free tier](https://ipinfo.io/products/free-ip-database) that maps IP ranges\\nto countries. We import the free database into IYP.\\n'}, {'organization': 'NRO', 'name': 'Extended allocation and assignment reports', 'url': 'https://www.nro.net/about/rirs/statistics', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/nro#readme', 'reference_name': 'nro.delegated_stats', 'readme_header': '# Number Resource Organization -- https://www.nro.net/\\n\\nThe Number Resource Organization (NRO) is the coordinating body for the world’s Regional Internet\\nRegistries (RIRs). The RIRs manage the distribution of Internet number resources (IP address space\\nand Autonomous System Numbers) within their respective regions.\\n\\nAs part of a joint RIR project to provide consistent and accessible Internet number resource\\nstatistics the NRO publishes [*Extended Allocation and Assignment\\nReports*](https://www.nro.net/about/rirs/statistics/) (also called *delegated stats*) that contain\\ninformation about assigned IP address ranges and AS numbers.\\n\\nEach line of the report is a record that either represents an IP address range or an AS number. The\\nrecord has a status and maps to an *opaque ID* that uniquely identifies a single organization.\\nFinally, the record contains a country code to which the organization belongs.\\n\\n**Note:** If the record is not assigned, the country code is `ZZ`, which will still be inserted into\\nIYP.\\n'}, {'organization': 'OONI', 'name': 'Facebook Messenger', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-019-facebook-messenger.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.facebookmessenger', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Header Field Manipulation Test', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-006-header-field-manipulation.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.httpheaderfieldmanipulation', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'HTTP Invalid Request Line Test', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-007-http-invalid-request-line.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.httpinvalidrequestline', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Signal', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-029-signal.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.osignal', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Psiphon', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-015-psiphon.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.psiphon', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'RiseupVPN', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-026-riseupvpn.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.riseupvpn', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'STUN reachability', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-025-stun-reachability.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.stunreachability', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Telegram', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-020-telegram.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.telegram', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Tor', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-023-tor.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.tor', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Tor using snowflake', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-030-torsf.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.torsf', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Vanilla Tor', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-016-vanilla-tor.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.vanillator', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Web Connectivity', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-017-web-connectivity.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.webconnectivity', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'WhatsApp', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-018-whatsapp.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.whatsapp', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OpenINTEL', 'name': 'Google CrUX', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.crux', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Infrastructure', 'url': 'https://openintel.nl/data/forward-dns/infrastructure/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.infra_ns', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Tranco Top 1M', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.tranco1m', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Cisco Umbrella Top 1M', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.umbrella1m', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'DNS Dependency Graph', 'url': 'https://dnsgraph.dacs.utwente.nl', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.dnsgraph_nl', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'DNS Dependency Graph', 'url': 'https://dnsgraph.dacs.utwente.nl', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.dnsgraph_rdns', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'Packet Clearing House', 'name': 'Daily routing snapshots', 'url': 'https://www.pch.net/resources/Routing_Data', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme', 'reference_name': 'pch.daily_routing_snapshots_v4', 'readme_header': '# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet\\'s operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \"show ip bgp\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n'}, {'organization': 'Packet Clearing House', 'name': 'Daily routing snapshots', 'url': 'https://www.pch.net/resources/Routing_Data', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme', 'reference_name': 'pch.daily_routing_snapshots_v6', 'readme_header': '# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet\\'s operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \"show ip bgp\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: fac', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.fac', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: ix', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.ix', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: ixlan', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.ixlan', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: netfac', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.netfac', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: org', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.org', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'RIPE NCC', 'name': 'AS names', 'url': 'https://ftp.ripe.net/ripe/asnames', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.as_names', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RPKI', 'url': 'https://ftp.ripe.net/ripe/rpki', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.roa', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RIPE Atlas measurement information', 'url': 'https://atlas.ripe.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.atlas_measurements', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RIPE Atlas probes', 'url': 'https://atlas.ripe.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.atlas_probes', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'SimulaMet', 'name': 'rDNS data', 'url': 'https://rir-data.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/simulamet#readme', 'reference_name': 'simulamet.rirdata_rdns', 'readme_header': '# rDNS RIR data -- https://rir-data.org/\\n\\n\"Lowering the Barriers to Working with Public RIR-Level Data\" is a joint project of\\nSimulaMet and the University of Twente with the goal of making WHOIS, route object\\ndelegation, and reverse DNS (rDNS) zone files published by Regional Internet Registries\\n(RIRs) more accessible.\\n\\nIYP imports the rDNS files in a simplified format to indicate which authoritative name\\nservers are responsible for a prefix. We do not model PTR records and the corresponding\\nhierarchy but instead add a simple MANAGED_BY link.\\n'}, {'organization': 'Stanford', 'name': 'ASdb dataset', 'url': 'https://asdb.stanford.edu', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/stanford#readme', 'reference_name': 'stanford.asdb', 'readme_header': \"# Stanford's ASdb -- https://asdb.stanford.edu/\\n\\nASdb is a research dataset that maps public autonomous systems (identified by \\nASN) to organizations and up to three industry types using data from business \\nintelligence databases, website classifiers, and a machine learning algorithm. \\n\"}, {'organization': 'Tranco', 'name': 'Tranco list', 'url': 'https://tranco-list.eu', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme', 'reference_name': 'tranco.top1m', 'readme_header': '# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n'}, {'organization': 'Virginia Tech', 'name': 'RoVista', 'url': 'https://rovista.netsecurelab.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/virginiatech#readme', 'reference_name': 'virginiatech.rovista', 'readme_header': '# RoVista -- https://rovista.netsecurelab.org/\\n\\n> RoVista aims to determine the Routing Origin Validation (ROV) status of network\\n> operators.\\n>\\n> RoV Scores are determined based on the number of RPKI-invalid prefixes reachable by an\\n> Autonomous System (AS). Consequently, a higher ROV score suggests that the AS can\\n> effectively filter more RPKI-invalid prefixes. However, it is important to note that\\n> the RoV score does not conclusively indicate whether an AS has actually implemented\\n> ROV or not, partly due to limitations in [the] framework and other contributing\\n> factors.\\n\\nIYP converts these scores (or ratios) to two Tags:\\n\\n- ASes with a ratio greater than 0.5 are categorized as `Validating RPKI ROV`\\n- ASes with a ratio of less or equal 0.5 are categorized as `Not Validating RPKI ROV`\\n'}, {'organization': 'World Bank', 'name': 'Indicators API: Country Population Indicator', 'url': 'https://www.worldbank.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/worldbank#readme', 'reference_name': 'worldbank.country_pop', 'readme_header': \"# World Bank's country population -- https://www.worldbank.org/en/home\\n\\n> The World Bank Group works in every major area of development. We provide a wide array of financial products and technical assistance, and we help countries share and apply innovative knowledge and solutions to the challenges they face.\\n\\n> The World Bank is like a cooperative, made up of 189 member countries. These member countries, or shareholders, are represented by a Board of Governors, who are the ultimate policymakers at the World Bank. Generally, the governors are member countries' ministers of finance or ministers of development. They meet once a year at the Annual Meetings of the Boards of Governors of the World Bank Group and the International Monetary Fund.\\n\"}], tool_call_id='call_zyt5h9wu', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 3, 850268, tzinfo=datetime.timezone.utc))], run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd'),\n",
       " ModelResponse(parts=[ThinkingPart(content='We need description of dataset related to tranco website ranking. Likely tranco.top1m dataset. The description is in readme_header. Provide best description. So cite that. Possibly also get resource doc for more detail. Use get_resource with name tranco.top1m, scheme dataset? The name is reference_name? The dataset reference_name is null? In list, tranco.top1m shows organization Tranco, name Tranco list, reference_name? It shows reference_name is null. Actually field reference_name is null. For get_resource need name reference_name for datasets, name otherwise. So we can use name \"tranco.top1m\"? Probably name = \"tranco.top1m\". Let\\'s call get_resource with scheme \"dataset\".', id='reasoning', provider_name='ollama'), ToolCallPart(tool_name='get_resource', args='{\"name\":\"tranco.top1m\",\"scheme\":\"dataset\"}', tool_call_id='call_5kvipmjp')], usage=RequestUsage(input_tokens=18465, output_tokens=191), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 8, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-878', finish_reason='tool_call', run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='get_resource', content={'organization': 'Tranco', 'name': 'Tranco list', 'url': 'https://tranco-list.eu', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme', 'reference_name': 'tranco.top1m', 'readme_header': '# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n', 'readme_content': \"# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n\\n## Graph representation\\n\\nThe rank of the domain is indicated by the `rank` property of the relationship.\\n\\n```Cypher\\n(:DomainName {name: 'google.com'})-[:RANK {rank: 1}]->(:Ranking {name: 'Tranco top 1M'})\\n```\\n\\n## Dependence\\n\\nThis crawler is not depending on other crawlers.\\n\"}, tool_call_id='call_5kvipmjp', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 8, 661610, tzinfo=datetime.timezone.utc))], run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd'),\n",
       " ModelResponse(parts=[TextPart(content='**Dataset:** **Tranco – “Tranco list”** (`tranco.top1m`)\\n\\n**Description (from the IYP documentation)**  \\n\\n> The Tranco list is a research‑oriented top‑sites ranking hardened against manipulation. It **combines the rankings of several source lists** to produce a daily list that is based on data of the past\\u202f30\\u202fdays.  \\n> IYP uses this data to create and annotate `DomainName` nodes.\\n\\n**Key points**\\n\\n- **Purpose:** Provides a stable, manipulation‑resistant ranking of the most popular web sites.  \\n- **Source:** Aggregates multiple existing ranking sources (see the Tranco methodology at https://tranco-list.eu/methodology).  \\n- **Coverage:** Daily list of the top\\u202f1\\u202fmillion domains, reflecting the last\\u202f30\\u202fdays of activity.  \\n- **IYP usage:** Each domain is represented as a `DomainName` node; its rank is stored on a `RANK` relationship to a `Ranking` node (e.g., `(:DomainName {name:\"google.com\"})-[:RANK {rank:1}]->(:Ranking {name:\"Tranco top 1M\"})`).  \\n- **Dependencies:** This crawler operates independently; it does not rely on other IYP crawlers.\\n\\n**Reference**  \\n- **URL:** https://tranco-list.eu  \\n- **Read‑me / documentation:** https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme  \\n\\nThis is the most comprehensive description available for the Tranco website‑ranking dataset within the Internet Yellow Pages.')], usage=RequestUsage(input_tokens=18990, output_tokens=341), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 27, 7, 49, 15, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'stop'}, provider_response_id='chatcmpl-950', finish_reason='stop', run_id='edbf49a3-12e7-4c7c-8c75-29809de143cd')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f986082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: list[Any], verbose: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Pretty print a list of Pydantic AI messages.\n",
    "\n",
    "    Args:\n",
    "        messages: List of ModelRequest and ModelResponse objects\n",
    "        verbose: If True, show additional metadata like timestamps, usage, etc.\n",
    "    \"\"\"\n",
    "    for i, msg in enumerate(messages):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Message {i + 1}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        # Determine message type\n",
    "        if hasattr(msg, \"kind\"):\n",
    "            if msg.kind == \"request\":\n",
    "                _print_request(msg, verbose)\n",
    "            elif msg.kind == \"response\":\n",
    "                _print_response(msg, verbose)\n",
    "        else:\n",
    "            print(f\"Unknown message type: {type(msg)}\")\n",
    "\n",
    "\n",
    "def _print_request(msg: Any, verbose: bool) -> None:\n",
    "    \"\"\"Print a ModelRequest message.\"\"\"\n",
    "    print(\"📤 REQUEST\")\n",
    "\n",
    "    if verbose and hasattr(msg, \"instructions\") and msg.instructions:\n",
    "        print(f\"\\nInstructions: {msg.instructions}\")\n",
    "\n",
    "    print(\"\\nParts:\")\n",
    "    for j, part in enumerate(msg.parts):\n",
    "        _print_request_part(part, j, verbose)\n",
    "\n",
    "\n",
    "def _print_response(msg: Any, verbose: bool) -> None:\n",
    "    \"\"\"Print a ModelResponse message.\"\"\"\n",
    "    print(\"📥 RESPONSE\")\n",
    "\n",
    "    if verbose:\n",
    "        if hasattr(msg, \"model_name\") and msg.model_name:\n",
    "            print(f\"Model: {msg.model_name}\")\n",
    "        if hasattr(msg, \"provider_name\") and msg.provider_name:\n",
    "            print(f\"Provider: {msg.provider_name}\")\n",
    "        if hasattr(msg, \"timestamp\"):\n",
    "            print(f\"Timestamp: {msg.timestamp}\")\n",
    "        if hasattr(msg, \"usage\"):\n",
    "            print(f\"Usage: {msg.usage}\")\n",
    "        if hasattr(msg, \"provider_request_id\") and msg.provider_request_id:\n",
    "            print(f\"Request ID: {msg.provider_request_id}\")\n",
    "        if hasattr(msg, \"provider_details\") and msg.provider_details:\n",
    "            print(f\"Provider Details: {msg.provider_details}\")\n",
    "        if hasattr(msg, \"finish_reason\") and msg.finish_reason:\n",
    "            print(f\"Finish Reason: {msg.finish_reason}\")\n",
    "\n",
    "    print(\"\\nParts:\")\n",
    "    for j, part in enumerate(msg.parts):\n",
    "        _print_response_part(part, j, verbose)\n",
    "\n",
    "\n",
    "def _print_request_part(part: Any, index: int, verbose: bool) -> None:\n",
    "    \"\"\"Print a single ModelRequestPart.\"\"\"\n",
    "    part_kind = getattr(part, \"part_kind\", \"unknown\")\n",
    "\n",
    "    print(f\"\\n  [{index}] {_get_part_icon(part_kind)} {part_kind.upper()}\")\n",
    "\n",
    "    if part_kind == \"system-prompt\":\n",
    "        print(f\"      Content: {_truncate(part.content)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"dynamic_ref\") and part.dynamic_ref:\n",
    "                print(f\"      Dynamic Ref: {part.dynamic_ref}\")\n",
    "\n",
    "    elif part_kind == \"user-prompt\":\n",
    "        content = part.content\n",
    "        if isinstance(content, str):\n",
    "            print(f\"      Content: {_truncate(content)}\")\n",
    "        elif isinstance(content, list):\n",
    "            print(f\"      Content (multipart):\")\n",
    "            for item in content:\n",
    "                _print_content_item(item)\n",
    "        if verbose and hasattr(part, \"timestamp\"):\n",
    "            print(f\"      Timestamp: {part.timestamp}\")\n",
    "\n",
    "    elif part_kind == \"tool-return\":\n",
    "        print(f\"      Tool: {part.tool_name}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        print(f\"      Content: {_format_json(part.content, indent=8)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"metadata\") and part.metadata:\n",
    "                print(f\"      Metadata: {part.metadata}\")\n",
    "\n",
    "    elif part_kind == \"retry-prompt\":\n",
    "        print(f\"      Tool: {part.tool_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id or 'N/A'}\")\n",
    "        if isinstance(part.content, str):\n",
    "            print(f\"      Content: {_truncate(part.content)}\")\n",
    "        else:\n",
    "            print(f\"      Content (errors): {len(part.content)} validation errors\")\n",
    "            if verbose:\n",
    "                for error in part.content[:3]:  # Show first 3 errors\n",
    "                    print(f\"        - {error}\")\n",
    "        if verbose and hasattr(part, \"timestamp\"):\n",
    "            print(f\"      Timestamp: {part.timestamp}\")\n",
    "\n",
    "\n",
    "def _print_response_part(part: Any, index: int, verbose: bool) -> None:\n",
    "    \"\"\"Print a single ModelResponsePart.\"\"\"\n",
    "    part_kind = getattr(part, \"part_kind\", \"unknown\")\n",
    "\n",
    "    print(f\"\\n  [{index}] {_get_part_icon(part_kind)} {part_kind.upper()}\")\n",
    "\n",
    "    if part_kind == \"text\":\n",
    "        print(f\"      Content: {_truncate(part.content)}\")\n",
    "\n",
    "    elif part_kind == \"thinking\":\n",
    "        print(f\"      Content: {_truncate(part.content)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"id\") and part.id:\n",
    "                print(f\"      ID: {part.id}\")\n",
    "            if hasattr(part, \"signature\") and part.signature:\n",
    "                print(f\"      Signature: {part.signature}\")\n",
    "\n",
    "    elif part_kind == \"tool-call\":\n",
    "        print(f\"      Tool: {part.tool_name}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        args = part.args\n",
    "        if isinstance(args, str):\n",
    "            print(f\"      Args (JSON): {_truncate(args)}\")\n",
    "        else:\n",
    "            print(f\"      Args: {_format_json(args, indent=8)}\")\n",
    "\n",
    "    elif part_kind == \"builtin-tool-call\":\n",
    "        print(f\"      Tool: {part.tool_name} (builtin)\")\n",
    "        print(f\"      Provider: {part.provider_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        args = part.args\n",
    "        if isinstance(args, str):\n",
    "            print(f\"      Args (JSON): {_truncate(args)}\")\n",
    "        else:\n",
    "            print(f\"      Args: {_format_json(args, indent=8)}\")\n",
    "\n",
    "    elif part_kind == \"builtin-tool-return\":\n",
    "        print(f\"      Tool: {part.tool_name} (builtin)\")\n",
    "        print(f\"      Provider: {part.provider_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        print(f\"      Content: {_format_json(part.content, indent=8)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"metadata\") and part.metadata:\n",
    "                print(f\"      Metadata: {part.metadata}\")\n",
    "\n",
    "\n",
    "def _print_content_item(item: Any) -> None:\n",
    "    \"\"\"Print a content item from multipart user prompt.\"\"\"\n",
    "    if isinstance(item, str):\n",
    "        print(f\"        - Text: {_truncate(item)}\")\n",
    "    elif hasattr(item, \"kind\"):\n",
    "        kind = item.kind\n",
    "        if kind == \"image-url\":\n",
    "            print(f\"        - Image URL: {item.url}\")\n",
    "        elif kind == \"video-url\":\n",
    "            print(f\"        - Video URL: {item.url}\")\n",
    "        elif kind == \"audio-url\":\n",
    "            print(f\"        - Audio URL: {item.url}\")\n",
    "        elif kind == \"document-url\":\n",
    "            print(f\"        - Document URL: {item.url}\")\n",
    "        elif kind == \"binary\":\n",
    "            media = item.media_type\n",
    "            size = len(item.data) if hasattr(item, \"data\") else 0\n",
    "            print(f\"        - Binary: {media} ({size} bytes)\")\n",
    "    elif hasattr(item, \"type\"):\n",
    "        print(f\"        - {item.type}: {item}\")\n",
    "    else:\n",
    "        print(f\"        - Unknown: {type(item)}\")\n",
    "\n",
    "\n",
    "def _get_part_icon(part_kind: str) -> str:\n",
    "    \"\"\"Get an emoji icon for the part kind.\"\"\"\n",
    "    icons = {\n",
    "        \"system-prompt\": \"⚙️\",\n",
    "        \"user-prompt\": \"👤\",\n",
    "        \"tool-return\": \"🔧\",\n",
    "        \"retry-prompt\": \"🔄\",\n",
    "        \"text\": \"💬\",\n",
    "        \"thinking\": \"🤔\",\n",
    "        \"tool-call\": \"🛠️\",\n",
    "        \"builtin-tool-call\": \"🏗️\",\n",
    "        \"builtin-tool-return\": \"🏗️\",\n",
    "    }\n",
    "    return icons.get(part_kind, \"❓\")\n",
    "\n",
    "\n",
    "def _truncate(text: str, max_length: int = 10000) -> str:\n",
    "    \"\"\"Truncate text to a maximum length.\"\"\"\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    return text[:max_length] + \"...\"\n",
    "\n",
    "\n",
    "def _format_json(obj: Any, indent: int = 0) -> str:\n",
    "    \"\"\"Format an object as JSON with proper indentation.\"\"\"\n",
    "    if obj is None:\n",
    "        return \"null\"\n",
    "\n",
    "    try:\n",
    "        if isinstance(obj, str):\n",
    "            # Try to parse as JSON if it's a string\n",
    "            try:\n",
    "                parsed = json.loads(obj)\n",
    "                return json.dumps(parsed, indent=2).replace(\"\\n\", \"\\n\" + \" \" * indent)\n",
    "            except:\n",
    "                return obj\n",
    "        else:\n",
    "            return json.dumps(obj, indent=2, default=str).replace(\n",
    "                \"\\n\", \"\\n\" + \" \" * indent\n",
    "            )\n",
    "    except:\n",
    "        return str(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cda3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Message 1\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] ⚙️ SYSTEM-PROMPT\n",
      "      Content: You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet).\n",
      "Use available tools to query the database or retrieve informations about the databse documentation. Query IYP cypher query if needed to reply to the user. If the user's request cannot be answered by IYP, simply say that you don't know\n",
      "      Timestamp: 2025-11-27 07:49:02.325287+00:00\n",
      "\n",
      "  [1] 👤 USER-PROMPT\n",
      "      Content: Give me the best description of the dataset related to tranco website ranking\n",
      "      Timestamp: 2025-11-27 07:49:02.325292+00:00\n",
      "\n",
      "================================================================================\n",
      "Message 2\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "Model: gpt-oss:120b\n",
      "Provider: ollama\n",
      "Timestamp: 2025-11-27 07:49:03+00:00\n",
      "Usage: RequestUsage(input_tokens=615, output_tokens=74)\n",
      "Request ID: chatcmpl-613\n",
      "Provider Details: {'finish_reason': 'tool_calls'}\n",
      "Finish Reason: tool_call\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🤔 THINKING\n",
      "      Content: We need to give best description of the dataset related to tranco website ranking. Use IYP dataset info. Need to list datasets then get resource for the dataset. So first list datasets to find name matching tranco. Use list_iyp_datasets.\n",
      "      ID: reasoning\n",
      "\n",
      "  [1] 🛠️ TOOL-CALL\n",
      "      Tool: list_iyp_datasets\n",
      "      Tool Call ID: call_zyt5h9wu\n",
      "      Args (JSON): {}\n",
      "\n",
      "================================================================================\n",
      "Message 3\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🔧 TOOL-RETURN\n",
      "      Tool: list_iyp_datasets\n",
      "      Tool Call ID: call_zyt5h9wu\n",
      "      Content: [\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"IXP route server looking glass snapshots\",\n",
      "            \"url\": \"https://github.com/alice-lg/alice-lg\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": null,\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"AMS-IX\",\n",
      "            \"url\": \"https://lg.ams-ix.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.amsix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"BCIX\",\n",
      "            \"url\": \"https://lg.bcix.de\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.bcix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"DE-CIX\",\n",
      "            \"url\": \"https://lg.de-cix.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.decix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"IX.br\",\n",
      "            \"url\": \"https://lg.ix.br\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.ixbr\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"LINX\",\n",
      "            \"url\": \"https://alice-rs.linx.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.linx\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"Megaport\",\n",
      "            \"url\": \"https://lg.megaport.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.megaport\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"Netnod\",\n",
      "            \"url\": \"https://lg.netnod.se\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.netnod\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"APNIC\",\n",
      "            \"name\": \"AS population estimate\",\n",
      "            \"url\": \"https://stats.labs.apnic.net/aspop\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/apnic#readme\",\n",
      "            \"reference_name\": \"apnic.eyeball\",\n",
      "            \"readme_header\": \"# APNIC population estimates -- https://labs.apnic.net/\\n\\nPopulation per AS estimated using an advertisement on Youtube. This dataset \\nprovides:\\n- the percentage of the population per country/AS\\n- AS ranking in terms of population\\n- AS names\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"as2rel\",\n",
      "            \"url\": \"https://data.bgpkit.com/as2rel\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.as2rel_v4\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"as2rel\",\n",
      "            \"url\": \"https://data.bgpkit.com/as2rel\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.as2rel_v6\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"peer-stats\",\n",
      "            \"url\": \"https://data.bgpkit.com/peer-stats\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.peerstats\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"pfx2as\",\n",
      "            \"url\": \"https://data.bgpkit.com/pfx2as\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.pfx2asn\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"Anycast prefix tags\",\n",
      "            \"url\": \"https://github.com/bgptools/anycast-prefixes\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.anycast_prefixes\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://bgp.tools/kb/api\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.as_names\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"AS tags\",\n",
      "            \"url\": \"https://bgp.tools/kb/api\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.tags\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS to Organizations\",\n",
      "            \"url\": \"https://catalog.caida.org/dataset/as_organizations\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.as2org\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS Rank\",\n",
      "            \"url\": \"https://doi.org/10.21986/CAIDA.DATA.AS-RANK\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.asrank\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS Relationships\",\n",
      "            \"url\": \"https://catalog.caida.org/dataset/as_relationships_serial_1\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.as_relationships_v4\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS Relationships\",\n",
      "            \"url\": \"https://catalog.caida.org/dataset/as_relationships_serial_1\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.as_relationships_v6\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"IXPs Dataset\",\n",
      "            \"url\": \"https://doi.org/10.21986/CAIDA.DATA.IXPS\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.ixs\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"IXPs Dataset\",\n",
      "            \"url\": \"https://doi.org/10.21986/CAIDA.DATA.IXPS\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.ix_asns\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cisco\",\n",
      "            \"name\": \"Umbrella Popularity List\",\n",
      "            \"url\": \"https://s3-us-west-1.amazonaws.com/umbrella-static/index.html\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco#readme\",\n",
      "            \"reference_name\": \"cisco.umbrella_top1m\",\n",
      "            \"readme_header\": \"# Cisco Umbrella -- https://umbrella-static.s3-us-west-1.amazonaws.com/index.html\\n\\nThe popularity list contains most queried domains (ranging from TLDs to FQDNs)\\nbased on passive DNS usage across the Umbrella global network.\\n\\nIYP uses this data to create and annotate DomainName and HostName nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Citizen Lab\",\n",
      "            \"name\": \"URL testing lists\",\n",
      "            \"url\": \"https://github.com/citizenlab/test-lists\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/citizenlab#readme\",\n",
      "            \"reference_name\": \"citizenlab.urldb\",\n",
      "            \"readme_header\": \"# Citizen Lab -- https://github.com/citizenlab/test-lists/blob/master/lists/\\n\\nCitizen lab's test lists are URL testing lists intended to help in testing URL censorship, divided by country codes. In addition to these local lists, the global list consists of a wide range of internationally relevant and popular websites, including sites with content that is perceived to be provocative or objectionable. The dataset tha maps URL to Category.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/datasets\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.ranking_bucket\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/dns/top/ases\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.dns_top_ases\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/dns/top/locations\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.dns_top_locations\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/ranking/top (top 100 domain names)\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.top100\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Emile Aben\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://github.com/emileaben/asnames\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/emileaben#readme\",\n",
      "            \"reference_name\": \"emileaben.as_names\",\n",
      "            \"readme_header\": \"# EmileAben's AS Names -- https://github.com/emileaben/asnames\\n\\nData collected by EmileAben's AS Names, including:\\n\\n- AS numbers\\n- AS names\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Google\",\n",
      "            \"name\": \"CrUX top 1M websites per country\",\n",
      "            \"url\": \"https://developer.chrome.com/docs/crux\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/google#readme\",\n",
      "            \"reference_name\": \"google.crux_top1m_country\",\n",
      "            \"readme_header\": \"# Google CrUX -- https://developer.chrome.com/docs/crux\\n\\nThe Chrome User Experience Report (CrUX for short) is a dataset collected by\\nGoogle that reflects how real-world Chrome users experience popular\\ndestinations on the web.\\n\\nCrUX data is collected from real browsers around the world, based on certain\\nbrowser options which determine user eligibility. A set of dimensions and metrics\\nare collected which allow site owners to determine how users experience their sites.\\n\\nIYP fetches CrUX's [top 1M popular websites per country](https://github.com/InternetHealthReport/crux-top-lists-country).\\nUnlike others, CrUX rankings are bucketed by rank magnitude order, not by\\nspecific rank. For example, ranks are 1000, 10k, 100k, or 1M.\\n\\nIn addition, CrUX ranks *origins* (e.g., https://www.google.com), not domain\\nor host names. In IYP we extract the hostname part of the origin and model this\\ndataset using the hostname.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"AS Hegemony\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#AS-dependency\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.local_hegemony_v4\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"AS Hegemony\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#AS-dependency\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.local_hegemony_v6\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"Country Dependency\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#Country-s-network-dependency\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.country_dependency\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"ROV\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#Route-Origin-Validation\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.rov\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Internet Intelligence Lab\",\n",
      "            \"name\": \"AS to Organization Mapping\",\n",
      "            \"url\": \"https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/inetintel#readme\",\n",
      "            \"reference_name\": \"inetintel.as_org\",\n",
      "            \"readme_header\": \"# Internet Intelligence Lab - Dataset: AS to Organization mapping -- https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\\n\\nThe dataset contains historical and current versions of the AS to Organization \\nmapping datasets. A mapping will be created between AS to its sibling ASes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IPinfo\",\n",
      "            \"name\": \"IP to Country Mapping\",\n",
      "            \"url\": \"https://ipinfo.io\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ipinfo#readme\",\n",
      "            \"reference_name\": \"ipinfo.ip_country\",\n",
      "            \"readme_header\": \"# IPinfo -- https://ipinfo.io/\\n\\nIPinfo is an IP geolocation service, that provides different kinds of IP databases,\\nincluding a [free tier](https://ipinfo.io/products/free-ip-database) that maps IP ranges\\nto countries. We import the free database into IYP.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"NRO\",\n",
      "            \"name\": \"Extended allocation and assignment reports\",\n",
      "            \"url\": \"https://www.nro.net/about/rirs/statistics\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/nro#readme\",\n",
      "            \"reference_name\": \"nro.delegated_stats\",\n",
      "            \"readme_header\": \"# Number Resource Organization -- https://www.nro.net/\\n\\nThe Number Resource Organization (NRO) is the coordinating body for the world\\u2019s Regional Internet\\nRegistries (RIRs). The RIRs manage the distribution of Internet number resources (IP address space\\nand Autonomous System Numbers) within their respective regions.\\n\\nAs part of a joint RIR project to provide consistent and accessible Internet number resource\\nstatistics the NRO publishes [*Extended Allocation and Assignment\\nReports*](https://www.nro.net/about/rirs/statistics/) (also called *delegated stats*) that contain\\ninformation about assigned IP address ranges and AS numbers.\\n\\nEach line of the report is a record that either represents an IP address range or an AS number. The\\nrecord has a status and maps to an *opaque ID* that uniquely identifies a single organization.\\nFinally, the record contains a country code to which the organization belongs.\\n\\n**Note:** If the record is not assigned, the country code is `ZZ`, which will still be inserted into\\nIYP.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Facebook Messenger\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-019-facebook-messenger.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.facebookmessenger\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Header Field Manipulation Test\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-006-header-field-manipulation.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.httpheaderfieldmanipulation\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"HTTP Invalid Request Line Test\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-007-http-invalid-request-line.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.httpinvalidrequestline\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Signal\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-029-signal.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.osignal\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Psiphon\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-015-psiphon.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.psiphon\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"RiseupVPN\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-026-riseupvpn.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.riseupvpn\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"STUN reachability\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-025-stun-reachability.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.stunreachability\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Telegram\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-020-telegram.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.telegram\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Tor\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-023-tor.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.tor\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Tor using snowflake\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-030-torsf.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.torsf\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Vanilla Tor\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-016-vanilla-tor.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.vanillator\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Web Connectivity\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-017-web-connectivity.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.webconnectivity\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"WhatsApp\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-018-whatsapp.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.whatsapp\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Google CrUX\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.crux\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Infrastructure\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/infrastructure/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.infra_ns\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Tranco Top 1M\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.tranco1m\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Cisco Umbrella Top 1M\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.umbrella1m\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"DNS Dependency Graph\",\n",
      "            \"url\": \"https://dnsgraph.dacs.utwente.nl\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.dnsgraph_nl\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"DNS Dependency Graph\",\n",
      "            \"url\": \"https://dnsgraph.dacs.utwente.nl\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.dnsgraph_rdns\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Packet Clearing House\",\n",
      "            \"name\": \"Daily routing snapshots\",\n",
      "            \"url\": \"https://www.pch.net/resources/Routing_Data\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme\",\n",
      "            \"reference_name\": \"pch.daily_routing_snapshots_v4\",\n",
      "            \"readme_header\": \"# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet's operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \\\"show ip bgp\\\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Packet Clearing House\",\n",
      "            \"name\": \"Daily routing snapshots\",\n",
      "            \"url\": \"https://www.pch.net/resources/Routing_Data\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme\",\n",
      "            \"reference_name\": \"pch.daily_routing_snapshots_v6\",\n",
      "            \"readme_header\": \"# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet's operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \\\"show ip bgp\\\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: fac\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.fac\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: ix\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.ix\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: ixlan\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.ixlan\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: netfac\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.netfac\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: org\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.org\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://ftp.ripe.net/ripe/asnames\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.as_names\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RPKI\",\n",
      "            \"url\": \"https://ftp.ripe.net/ripe/rpki\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.roa\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RIPE Atlas measurement information\",\n",
      "            \"url\": \"https://atlas.ripe.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.atlas_measurements\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RIPE Atlas probes\",\n",
      "            \"url\": \"https://atlas.ripe.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.atlas_probes\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"SimulaMet\",\n",
      "            \"name\": \"rDNS data\",\n",
      "            \"url\": \"https://rir-data.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/simulamet#readme\",\n",
      "            \"reference_name\": \"simulamet.rirdata_rdns\",\n",
      "            \"readme_header\": \"# rDNS RIR data -- https://rir-data.org/\\n\\n\\\"Lowering the Barriers to Working with Public RIR-Level Data\\\" is a joint project of\\nSimulaMet and the University of Twente with the goal of making WHOIS, route object\\ndelegation, and reverse DNS (rDNS) zone files published by Regional Internet Registries\\n(RIRs) more accessible.\\n\\nIYP imports the rDNS files in a simplified format to indicate which authoritative name\\nservers are responsible for a prefix. We do not model PTR records and the corresponding\\nhierarchy but instead add a simple MANAGED_BY link.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Stanford\",\n",
      "            \"name\": \"ASdb dataset\",\n",
      "            \"url\": \"https://asdb.stanford.edu\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/stanford#readme\",\n",
      "            \"reference_name\": \"stanford.asdb\",\n",
      "            \"readme_header\": \"# Stanford's ASdb -- https://asdb.stanford.edu/\\n\\nASdb is a research dataset that maps public autonomous systems (identified by \\nASN) to organizations and up to three industry types using data from business \\nintelligence databases, website classifiers, and a machine learning algorithm. \\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Tranco\",\n",
      "            \"name\": \"Tranco list\",\n",
      "            \"url\": \"https://tranco-list.eu\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme\",\n",
      "            \"reference_name\": \"tranco.top1m\",\n",
      "            \"readme_header\": \"# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Virginia Tech\",\n",
      "            \"name\": \"RoVista\",\n",
      "            \"url\": \"https://rovista.netsecurelab.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/virginiatech#readme\",\n",
      "            \"reference_name\": \"virginiatech.rovista\",\n",
      "            \"readme_header\": \"# RoVista -- https://rovista.netsecurelab.org/\\n\\n> RoVista aims to determine the Routing Origin Validation (ROV) status of network\\n> operators.\\n>\\n> RoV Scores are determined based on the number of RPKI-invalid prefixes reachable by an\\n> Autonomous System (AS). Consequently, a higher ROV score suggests that the AS can\\n> effectively filter more RPKI-invalid prefixes. However, it is important to note that\\n> the RoV score does not conclusively indicate whether an AS has actually implemented\\n> ROV or not, partly due to limitations in [the] framework and other contributing\\n> factors.\\n\\nIYP converts these scores (or ratios) to two Tags:\\n\\n- ASes with a ratio greater than 0.5 are categorized as `Validating RPKI ROV`\\n- ASes with a ratio of less or equal 0.5 are categorized as `Not Validating RPKI ROV`\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"World Bank\",\n",
      "            \"name\": \"Indicators API: Country Population Indicator\",\n",
      "            \"url\": \"https://www.worldbank.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/worldbank#readme\",\n",
      "            \"reference_name\": \"worldbank.country_pop\",\n",
      "            \"readme_header\": \"# World Bank's country population -- https://www.worldbank.org/en/home\\n\\n> The World Bank Group works in every major area of development. We provide a wide array of financial products and technical assistance, and we help countries share and apply innovative knowledge and solutions to the challenges they face.\\n\\n> The World Bank is like a cooperative, made up of 189 member countries. These member countries, or shareholders, are represented by a Board of Governors, who are the ultimate policymakers at the World Bank. Generally, the governors are member countries' ministers of finance or ministers of development. They meet once a year at the Annual Meetings of the Boards of Governors of the World Bank Group and the International Monetary Fund.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      Timestamp: 2025-11-27 07:49:03.850268+00:00\n",
      "\n",
      "================================================================================\n",
      "Message 4\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "Model: gpt-oss:120b\n",
      "Provider: ollama\n",
      "Timestamp: 2025-11-27 07:49:08+00:00\n",
      "Usage: RequestUsage(input_tokens=18465, output_tokens=191)\n",
      "Request ID: chatcmpl-878\n",
      "Provider Details: {'finish_reason': 'tool_calls'}\n",
      "Finish Reason: tool_call\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🤔 THINKING\n",
      "      Content: We need description of dataset related to tranco website ranking. Likely tranco.top1m dataset. The description is in readme_header. Provide best description. So cite that. Possibly also get resource doc for more detail. Use get_resource with name tranco.top1m, scheme dataset? The name is reference_name? The dataset reference_name is null? In list, tranco.top1m shows organization Tranco, name Tranco list, reference_name? It shows reference_name is null. Actually field reference_name is null. For get_resource need name reference_name for datasets, name otherwise. So we can use name \"tranco.top1m\"? Probably name = \"tranco.top1m\". Let's call get_resource with scheme \"dataset\".\n",
      "      ID: reasoning\n",
      "\n",
      "  [1] 🛠️ TOOL-CALL\n",
      "      Tool: get_resource\n",
      "      Tool Call ID: call_5kvipmjp\n",
      "      Args (JSON): {\"name\":\"tranco.top1m\",\"scheme\":\"dataset\"}\n",
      "\n",
      "================================================================================\n",
      "Message 5\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🔧 TOOL-RETURN\n",
      "      Tool: get_resource\n",
      "      Tool Call ID: call_5kvipmjp\n",
      "      Content: {\n",
      "          \"organization\": \"Tranco\",\n",
      "          \"name\": \"Tranco list\",\n",
      "          \"url\": \"https://tranco-list.eu\",\n",
      "          \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme\",\n",
      "          \"reference_name\": \"tranco.top1m\",\n",
      "          \"readme_header\": \"# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n\",\n",
      "          \"readme_content\": \"# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n\\n## Graph representation\\n\\nThe rank of the domain is indicated by the `rank` property of the relationship.\\n\\n```Cypher\\n(:DomainName {name: 'google.com'})-[:RANK {rank: 1}]->(:Ranking {name: 'Tranco top 1M'})\\n```\\n\\n## Dependence\\n\\nThis crawler is not depending on other crawlers.\\n\"\n",
      "        }\n",
      "      Timestamp: 2025-11-27 07:49:08.661610+00:00\n",
      "\n",
      "================================================================================\n",
      "Message 6\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "Model: gpt-oss:120b\n",
      "Provider: ollama\n",
      "Timestamp: 2025-11-27 07:49:15+00:00\n",
      "Usage: RequestUsage(input_tokens=18990, output_tokens=341)\n",
      "Request ID: chatcmpl-950\n",
      "Provider Details: {'finish_reason': 'stop'}\n",
      "Finish Reason: stop\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 💬 TEXT\n",
      "      Content: **Dataset:** **Tranco – “Tranco list”** (`tranco.top1m`)\n",
      "\n",
      "**Description (from the IYP documentation)**  \n",
      "\n",
      "> The Tranco list is a research‑oriented top‑sites ranking hardened against manipulation. It **combines the rankings of several source lists** to produce a daily list that is based on data of the past 30 days.  \n",
      "> IYP uses this data to create and annotate `DomainName` nodes.\n",
      "\n",
      "**Key points**\n",
      "\n",
      "- **Purpose:** Provides a stable, manipulation‑resistant ranking of the most popular web sites.  \n",
      "- **Source:** Aggregates multiple existing ranking sources (see the Tranco methodology at https://tranco-list.eu/methodology).  \n",
      "- **Coverage:** Daily list of the top 1 million domains, reflecting the last 30 days of activity.  \n",
      "- **IYP usage:** Each domain is represented as a `DomainName` node; its rank is stored on a `RANK` relationship to a `Ranking` node (e.g., `(:DomainName {name:\"google.com\"})-[:RANK {rank:1}]->(:Ranking {name:\"Tranco top 1M\"})`).  \n",
      "- **Dependencies:** This crawler operates independently; it does not rely on other IYP crawlers.\n",
      "\n",
      "**Reference**  \n",
      "- **URL:** https://tranco-list.eu  \n",
      "- **Read‑me / documentation:** https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme  \n",
      "\n",
      "This is the most comprehensive description available for the Tranco website‑ranking dataset within the Internet Yellow Pages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2272486/1214004877.py:54: DeprecationWarning: `provider_request_id` is deprecated, use `provider_response_id` instead\n",
      "  if hasattr(msg, \"provider_request_id\") and msg.provider_request_id:\n",
      "/tmp/ipykernel_2272486/1214004877.py:55: DeprecationWarning: `provider_request_id` is deprecated, use `provider_response_id` instead\n",
      "  print(f\"Request ID: {msg.provider_request_id}\")\n"
     ]
    }
   ],
   "source": [
    "pretty_print_messages(result.all_messages(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ef66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result2 = agent.run_sync(\"Run one of the cypher query you found in the documentation.\", message_history=result.new_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
