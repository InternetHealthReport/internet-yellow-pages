{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49823a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell runs only once per kernel restart.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"_executed_once\" not in get_ipython().user_ns:\n",
    "    print(\"This cell runs only once per kernel restart.\")\n",
    "    get_ipython().user_ns[\"_executed_once\"] = True\n",
    "\n",
    "    import nest_asyncio\n",
    "\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deda58b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**IXPs in IYP – the dataset and the data model**\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣  Which dataset holds the IXP information?\n",
      "\n",
      "The Internet Yellow Pages (IYP) gets authoritative IXP data from **PeeringDB**.  \n",
      "The specific IYP dataset that you can query is:\n",
      "\n",
      "```\n",
      "dataset://peeringdb.ix\n",
      "```\n",
      "\n",
      "(You can also look at the related *fac* and *net* datasets for facilities and member networks.)\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣  How are IXPs modeled in the IYP knowledge‑graph?\n",
      "\n",
      "The PeeringDB crawler creates a rich graph that captures **IXPs, their facilities, LANs, member ASes, organisations and auxiliary data**.  \n",
      "Below is a concise summary of the node types and the relationships that appear for an IXP.\n",
      "\n",
      "| **Node type** | **Key property** | **What it represents** |\n",
      "|---------------|------------------|------------------------|\n",
      "| `(:IXP)` | `name` | The Internet Exchange Point itself |\n",
      "| `(:Facility)` | `name` | Co‑location/data‑center where the IXP is housed |\n",
      "| `(:Country)` | `country_code` | Country of the IXP (or facility) |\n",
      "| `(:Organization)` | `name` | The legal entity that runs the IXP |\n",
      "| `(:PeeringLAN)` | `prefix` (e.g. `2001:7f8:1::/48`) | The VLAN / prefix used for the IXP’s peering LAN |\n",
      "| `(:AS)` | `asn` | Autonomous System of a member network |\n",
      "| `(:PeeringdbIXID)` | `id` | Raw PeeringDB identifier for the IXP |\n",
      "| `(:PeeringdbFacID)` | `id` | Raw PeeringDB identifier for a facility |\n",
      "| `(:PeeringdbNetID)` | `id` | Raw PeeringDB identifier for a member network |\n",
      "| `(:Name)` | `name` | Human‑readable names (IXP name, facility name, AS name) |\n",
      "| `(:URL)` | `url` | Web site of the IXP, facility or member network |\n",
      "\n",
      "### Core relationships\n",
      "\n",
      "```cypher\n",
      "(:IXP)-[:COUNTRY]->(:Country)                // where the IXP is located\n",
      "(:IXP)-[:EXTERNAL_ID]->(:PeeringdbIXID)      // raw PeeringDB record\n",
      "(:IXP)-[:LOCATED_IN]->(:Facility)            // data‑center that hosts it\n",
      "(:IXP)-[:MANAGED_BY]->(:Organization)        // owning organisation\n",
      "(:IXP)-[:NAME]->(:Name)                      // IXP name node\n",
      "(:IXP)-[:WEBSITE]->(:URL)                    // IXP website\n",
      "\n",
      "(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)      // raw PeeringDB net record\n",
      "(:AS)-[:LOCATED_IN]->(:Facility)             // member’s presence in a facility\n",
      "(:AS)-[:MANAGED_BY]->(:Organization)         // member operator\n",
      "(:AS)-[:MEMBER_OF]->(:IXP)                   // AS is a member of this IXP\n",
      "(:AS)-[:NAME]->(:Name)                       // AS name\n",
      "(:AS)-[:WEBSITE]->(:URL)                     // member’s website\n",
      "\n",
      "(:PeeringLAN)-[:MANAGED_BY]->(:IXP)          // LAN belongs to the IXP\n",
      "```\n",
      "\n",
      "*Additional relationship properties* (e.g., raw JSON blobs) are attached to the `EXTERNAL_ID` edges – they hold the full API payload from PeeringDB for later inspection.\n",
      "\n",
      "### Example query (from the documentation)\n",
      "\n",
      "```cypher\n",
      "MATCH (as:AS {asn: 2497})-[r0:EXTERNAL_ID]->(n0:PeeringdbNetID)\n",
      "MATCH (as)-[r1:LOCATED_IN]->(fac:Facility {name:'IIJ Ikebukuro DC'})\n",
      "MATCH (as)-[r2:MANAGED_BY]->(org:Organization)\n",
      "MATCH (as)-[r3:MEMBER_OF]->(ix:IXP {name:'DE-CIX Frankfurt'})\n",
      "MATCH (as)-[r4:NAME]->(n3:Name)\n",
      "MATCH (as)-[r5:WEBSITE]->(n4:URL)\n",
      "MATCH (pfx:PeeringLAN {af:4})-[r6:MANAGED_BY]->(ix)\n",
      "MATCH (ix)-[r7:COUNTRY]->(c:Country)\n",
      "MATCH (ix)-[r8:EXTERNAL_ID]->(ixid:PeeringdbIXID)\n",
      "MATCH (ix)-[r9:LOCATED_IN]->(fac2:Facility {name:'Global Switch Frankfurt'})\n",
      "MATCH (ix)-[r10:MANAGED_BY]->(org2:Organization)\n",
      "MATCH (ix)-[r11:NAME]->(n9:Name)\n",
      "MATCH (ix)-[r12:WEBSITE]->(n10:URL)\n",
      "RETURN as, ix, pfx,\n",
      "       n0,n1,n2,n3,n4,n5,n6,n7,n8,n9,n10,\n",
      "       r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12;\n",
      "```\n",
      "\n",
      "The visualisation produced by this query is the **full IXP sub‑graph** (IXP, its facility, country, member ASes, LAN, etc.).\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣  Quick way to explore the data\n",
      "\n",
      "If you have access to the IYP GraphQL/Neo4j endpoint, you can run a short query to list all IXPs:\n",
      "\n",
      "```cypher\n",
      "MATCH (i:IXP) RETURN i.name AS ixp_name, i.id AS ixp_id, i.country_code AS country\n",
      "ORDER BY ixp_name;\n",
      "```\n",
      "\n",
      "Or to see a specific IXP’s members:\n",
      "\n",
      "```cypher\n",
      "MATCH (i:IXP {name:\"DE-CIX Frankfurt\"})<-[:MEMBER_OF]-(m:AS)\n",
      "RETURN m.asn AS member_asn, m.name AS member_name\n",
      "ORDER BY m.asn;\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "\n",
      "* **Dataset** – `peeringdb.ix` (PeeringDB’s IXP API data).  \n",
      "* **Model** – IXP → Country, Facility, Organization, PeeringLAN, Member ASes, each with explicit `EXTERNAL_ID` nodes for the raw PeeringDB payload and `NAME`/`URL` auxiliary nodes.  \n",
      "* **Graph shape** – Rich, typed nodes with clear relationships (`MEMBER_OF`, `LOCATED_IN`, `MANAGED_BY`, `MANAGED_BY` for LANs, etc.), enabling easy traversal from an IXP to its members, location, and underlying data‑center.  \n",
      "\n",
      "You can now query or visualise IXPs directly in IYP using the above model. Happy exploring!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "\n",
    "\n",
    "# ollama_model = OpenAIChatModel(\n",
    "#     model_name=\"qwen3:8b\",\n",
    "#     provider=OllamaProvider(base_url=\"http://localhost:11434/v1\"),\n",
    "# )\n",
    "\n",
    "ollama_model = OpenAIChatModel(\n",
    "    model_name=\"gpt-oss:120b-cloud\",\n",
    "    provider=OllamaProvider(base_url=\"https://ollama.com/v1\",\n",
    "                            api_key=os.getenv(\"OLLAMA_API_KEY\")),\n",
    ")\n",
    "\n",
    "server = MCPServerStreamableHTTP(\"http://localhost:8001/mcp\")\n",
    "system_prompt= \"\"\"You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet) documentation.\n",
    "Use available tools to retrieve informations. Always assume the answer to the user request is in the documentation (it's your job to find it)\"\"\"\n",
    "agent = Agent(ollama_model, toolsets=[server], system_prompt=system_prompt)\n",
    "\n",
    "result = agent.run_sync(\n",
    "    \"Find the dataset associated to IXPs and show me how IXPs are modeled in IYP\"\n",
    ")\n",
    "print(result.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4328de7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content=\"You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet) documentation.\\nUse available tools to retrieve informations. Always assume the answer to the user request is in the documentation (it's your job to find it)\", timestamp=datetime.datetime(2025, 11, 21, 10, 12, 30, 874414, tzinfo=datetime.timezone.utc)), UserPromptPart(content='Find the dataset associated to IXPs and show me how IXPs are modeled in IYP', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 30, 874420, tzinfo=datetime.timezone.utc))], run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0'),\n",
       " ModelResponse(parts=[ThinkingPart(content=\"We need to find dataset associated to IXPs and then describe modeling of IXPs in IYP. Use list_datasets then get_resource for dataset about IXPs. Let's list datasets.\", id='reasoning', provider_name='ollama'), ToolCallPart(tool_name='list_datasets', args='{}', tool_call_id='call_8gnx9bue')], usage=RequestUsage(input_tokens=222, output_tokens=58), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 32, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-315', finish_reason='tool_call', run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='list_datasets', content=[{'organization': 'Alice-LG', 'name': 'IXP route server looking glass snapshots', 'url': 'https://github.com/alice-lg/alice-lg', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': None, 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'AMS-IX', 'url': 'https://lg.ams-ix.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.amsix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'BCIX', 'url': 'https://lg.bcix.de', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.bcix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'DE-CIX', 'url': 'https://lg.de-cix.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.decix', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'IX.br', 'url': 'https://lg.ix.br', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.ixbr', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'LINX', 'url': 'https://alice-rs.linx.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.linx', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'Megaport', 'url': 'https://lg.megaport.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.megaport', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'Alice-LG', 'name': 'Netnod', 'url': 'https://lg.netnod.se', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme', 'reference_name': 'alice_lg.netnod', 'readme_header': '# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n'}, {'organization': 'APNIC', 'name': 'AS population estimate', 'url': 'https://stats.labs.apnic.net/aspop', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/apnic#readme', 'reference_name': 'apnic.eyeball', 'readme_header': '# APNIC population estimates -- https://labs.apnic.net/\\n\\nPopulation per AS estimated using an advertisement on Youtube. This dataset \\nprovides:\\n- the percentage of the population per country/AS\\n- AS ranking in terms of population\\n- AS names\\n\\n'}, {'organization': 'BGPKIT', 'name': 'as2rel', 'url': 'https://data.bgpkit.com/as2rel', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.as2rel_v4, bgpkit.as2rel_v6', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'BGPKIT', 'name': 'peer-stats', 'url': 'https://data.bgpkit.com/peer-stats', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.peerstats', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'BGPKIT', 'name': 'pfx2as', 'url': 'https://data.bgpkit.com/pfx2as', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme', 'reference_name': 'bgpkit.pfx2asn', 'readme_header': \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"}, {'organization': 'bgp.tools', 'name': 'Anycast prefix tags', 'url': 'https://github.com/bgptools/anycast-prefixes', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.anycast_prefixes', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'bgp.tools', 'name': 'AS names', 'url': 'https://bgp.tools/kb/api', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.as_names', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'bgp.tools', 'name': 'AS tags', 'url': 'https://bgp.tools/kb/api', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme', 'reference_name': 'bgptools.tags', 'readme_header': '# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n'}, {'organization': 'CAIDA', 'name': 'AS to Organizations', 'url': 'https://catalog.caida.org/dataset/as_organizations', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.as2org', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'AS Rank', 'url': 'https://doi.org/10.21986/CAIDA.DATA.AS-RANK', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.asrank', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'AS Relationships', 'url': 'https://catalog.caida.org/dataset/as_relationships_serial_1', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.as_relationships_v4, caida.as_relationships_v6', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'CAIDA', 'name': 'IXPs Dataset', 'url': 'https://doi.org/10.21986/CAIDA.DATA.IXPS', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme', 'reference_name': 'caida.ixs, caida.ix_asns', 'readme_header': '# CAIDA -- https://caida.org\\n'}, {'organization': 'Cisco', 'name': 'Umbrella Popularity List', 'url': 'https://s3-us-west-1.amazonaws.com/umbrella-static/index.html', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco#readme', 'reference_name': 'cisco.umbrella_top1m', 'readme_header': '# Cisco Umbrella -- https://umbrella-static.s3-us-west-1.amazonaws.com/index.html\\n\\nThe popularity list contains most queried domains (ranging from TLDs to FQDNs)\\nbased on passive DNS usage across the Umbrella global network.\\n\\nIYP uses this data to create and annotate DomainName and HostName nodes.\\n'}, {'organization': 'Citizen Lab', 'name': 'URL testing lists', 'url': 'https://github.com/citizenlab/test-lists', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/citizenlab#readme', 'reference_name': 'citizenlab.urldb', 'readme_header': \"# Citizen Lab -- https://github.com/citizenlab/test-lists/blob/master/lists/\\n\\nCitizen lab's test lists are URL testing lists intended to help in testing URL censorship, divided by country codes. In addition to these local lists, the global list consists of a wide range of internationally relevant and popular websites, including sites with content that is perceived to be provocative or objectionable. The dataset tha maps URL to Category.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/datasets', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.ranking_bucket', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/dns/top/ases', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.dns_top_ases', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/dns/top/locations', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.dns_top_locations', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Cloudflare', 'name': 'Cloudflare Radar API endpoint radar/ranking/top (top 100 domain names)', 'url': 'https://radar.cloudflare.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme', 'reference_name': 'cloudflare.top100', 'readme_header': \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"}, {'organization': 'Emile Aben', 'name': 'AS names', 'url': 'https://github.com/emileaben/asnames', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/emileaben#readme', 'reference_name': 'emileaben.as_names', 'readme_header': \"# EmileAben's AS Names -- https://github.com/emileaben/asnames\\n\\nData collected by EmileAben's AS Names, including:\\n\\n- AS numbers\\n- AS names\\n\"}, {'organization': 'Google', 'name': 'CrUX top 1M websites per country', 'url': 'https://developer.chrome.com/docs/crux', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/google#readme', 'reference_name': 'google.crux_top1m_country', 'readme_header': \"# Google CrUX -- https://developer.chrome.com/docs/crux\\n\\nThe Chrome User Experience Report (CrUX for short) is a dataset collected by\\nGoogle that reflects how real-world Chrome users experience popular\\ndestinations on the web.\\n\\nCrUX data is collected from real browsers around the world, based on certain\\nbrowser options which determine user eligibility. A set of dimensions and metrics\\nare collected which allow site owners to determine how users experience their sites.\\n\\nIYP fetches CrUX's [top 1M popular websites per country](https://github.com/InternetHealthReport/crux-top-lists-country).\\nUnlike others, CrUX rankings are bucketed by rank magnitude order, not by\\nspecific rank. For example, ranks are 1000, 10k, 100k, or 1M.\\n\\nIn addition, CrUX ranks *origins* (e.g., https://www.google.com), not domain\\nor host names. In IYP we extract the hostname part of the origin and model this\\ndataset using the hostname.\\n\"}, {'organization': 'IHR', 'name': 'AS Hegemony', 'url': 'https://www.ihr.live/en/documentation#AS-dependency', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.local_hegemony_v4, ihr.local_hegemony_v6', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'IHR', 'name': 'Country Dependency', 'url': 'https://www.ihr.live/en/documentation#Country-s-network-dependency', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.country_dependency', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'IHR', 'name': 'ROV', 'url': 'https://www.ihr.live/en/documentation#Route-Origin-Validation', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme', 'reference_name': 'ihr.rov', 'readme_header': \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"}, {'organization': 'Internet Intelligence Lab', 'name': 'AS to Organization Mapping', 'url': 'https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/inetintel#readme', 'reference_name': 'inetintel.as_org', 'readme_header': '# Internet Intelligence Lab - Dataset: AS to Organization mapping -- https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\\n\\nThe dataset contains historical and current versions of the AS to Organization \\nmapping datasets. A mapping will be created between AS to its sibling ASes.\\n'}, {'organization': 'IPinfo', 'name': 'IP to Country Mapping', 'url': 'https://ipinfo.io', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ipinfo#readme', 'reference_name': 'ipinfo.ip_country', 'readme_header': '# IPinfo -- https://ipinfo.io/\\n\\nIPinfo is an IP geolocation service, that provides different kinds of IP databases,\\nincluding a [free tier](https://ipinfo.io/products/free-ip-database) that maps IP ranges\\nto countries. We import the free database into IYP.\\n'}, {'organization': 'NRO', 'name': 'Extended allocation and assignment reports', 'url': 'https://www.nro.net/about/rirs/statistics', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/nro#readme', 'reference_name': 'nro.delegated_stats', 'readme_header': '# Number Resource Organization -- https://www.nro.net/\\n\\nThe Number Resource Organization (NRO) is the coordinating body for the world’s Regional Internet\\nRegistries (RIRs). The RIRs manage the distribution of Internet number resources (IP address space\\nand Autonomous System Numbers) within their respective regions.\\n\\nAs part of a joint RIR project to provide consistent and accessible Internet number resource\\nstatistics the NRO publishes [*Extended Allocation and Assignment\\nReports*](https://www.nro.net/about/rirs/statistics/) (also called *delegated stats*) that contain\\ninformation about assigned IP address ranges and AS numbers.\\n\\nEach line of the report is a record that either represents an IP address range or an AS number. The\\nrecord has a status and maps to an *opaque ID* that uniquely identifies a single organization.\\nFinally, the record contains a country code to which the organization belongs.\\n\\n**Note:** If the record is not assigned, the country code is `ZZ`, which will still be inserted into\\nIYP.\\n'}, {'organization': 'OONI', 'name': 'Facebook Messenger', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-019-facebook-messenger.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.facebookmessenger', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Header Field Manipulation Test', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-006-header-field-manipulation.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.httpheaderfieldmanipulation', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'HTTP Invalid Request Line Test', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-007-http-invalid-request-line.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.httpinvalidrequestline', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Signal', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-029-signal.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.osignal', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Psiphon', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-015-psiphon.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.psiphon', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'RiseupVPN', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-026-riseupvpn.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.riseupvpn', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'STUN reachability', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-025-stun-reachability.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.stunreachability', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Telegram', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-020-telegram.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.telegram', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Tor', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-023-tor.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.tor', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Tor using snowflake', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-030-torsf.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.torsf', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Vanilla Tor', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-016-vanilla-tor.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.vanillator', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'Web Connectivity', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-017-web-connectivity.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.webconnectivity', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OONI', 'name': 'WhatsApp', 'url': 'https://github.com/ooni/spec/blob/master/nettests/ts-018-whatsapp.md', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme', 'reference_name': 'ooni.whatsapp', 'readme_header': '# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n'}, {'organization': 'OpenINTEL', 'name': 'Google CrUX', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.crux', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Infrastructure', 'url': 'https://openintel.nl/data/forward-dns/infrastructure/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.infra_ns', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Tranco Top 1M', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.tranco1m', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'Cisco Umbrella Top 1M', 'url': 'https://openintel.nl/data/forward-dns/top-lists/', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.umbrella1m', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'OpenINTEL', 'name': 'DNS Dependency Graph', 'url': 'https://dnsgraph.dacs.utwente.nl', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme', 'reference_name': 'openintel.dnsgraph_nl, openintel.dnsgraph_rdns', 'readme_header': '# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n'}, {'organization': 'Packet Clearing House', 'name': 'Daily routing snapshots', 'url': 'https://www.pch.net/resources/Routing_Data', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme', 'reference_name': 'pch.daily_routing_snapshots_v4, pch.daily_routing_snapshots_v6', 'readme_header': '# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet\\'s operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \"show ip bgp\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: fac', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.fac', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: ix', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.ix', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: ixlan', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.ixlan', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: netfac', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.netfac', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'PeeringDB', 'name': 'API endpoint: org', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.org', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n'}, {'organization': 'RIPE NCC', 'name': 'AS names', 'url': 'https://ftp.ripe.net/ripe/asnames', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.as_names', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RPKI', 'url': 'https://ftp.ripe.net/ripe/rpki', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.roa', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RIPE Atlas measurement information', 'url': 'https://atlas.ripe.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.atlas_measurements', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'RIPE NCC', 'name': 'RIPE Atlas probes', 'url': 'https://atlas.ripe.net', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme', 'reference_name': 'ripe.atlas_probes', 'readme_header': '# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE‘s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n'}, {'organization': 'SimulaMet', 'name': 'rDNS data', 'url': 'https://rir-data.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/simulamet#readme', 'reference_name': 'simulamet.rirdata_rdns', 'readme_header': '# rDNS RIR data -- https://rir-data.org/\\n\\n\"Lowering the Barriers to Working with Public RIR-Level Data\" is a joint project of\\nSimulaMet and the University of Twente with the goal of making WHOIS, route object\\ndelegation, and reverse DNS (rDNS) zone files published by Regional Internet Registries\\n(RIRs) more accessible.\\n\\nIYP imports the rDNS files in a simplified format to indicate which authoritative name\\nservers are responsible for a prefix. We do not model PTR records and the corresponding\\nhierarchy but instead add a simple MANAGED_BY link.\\n'}, {'organization': 'Stanford', 'name': 'ASdb dataset', 'url': 'https://asdb.stanford.edu', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/stanford#readme', 'reference_name': 'stanford.asdb', 'readme_header': \"# Stanford's ASdb -- https://asdb.stanford.edu/\\n\\nASdb is a research dataset that maps public autonomous systems (identified by \\nASN) to organizations and up to three industry types using data from business \\nintelligence databases, website classifiers, and a machine learning algorithm. \\n\"}, {'organization': 'Tranco', 'name': 'Tranco list', 'url': 'https://tranco-list.eu', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme', 'reference_name': 'tranco.top1m', 'readme_header': '# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n'}, {'organization': 'Virginia Tech', 'name': 'RoVista', 'url': 'https://rovista.netsecurelab.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/virginiatech#readme', 'reference_name': 'virginiatech.rovista', 'readme_header': '# RoVista -- https://rovista.netsecurelab.org/\\n\\n> RoVista aims to determine the Routing Origin Validation (ROV) status of network\\n> operators.\\n>\\n> RoV Scores are determined based on the number of RPKI-invalid prefixes reachable by an\\n> Autonomous System (AS). Consequently, a higher ROV score suggests that the AS can\\n> effectively filter more RPKI-invalid prefixes. However, it is important to note that\\n> the RoV score does not conclusively indicate whether an AS has actually implemented\\n> ROV or not, partly due to limitations in [the] framework and other contributing\\n> factors.\\n\\nIYP converts these scores (or ratios) to two Tags:\\n\\n- ASes with a ratio greater than 0.5 are categorized as `Validating RPKI ROV`\\n- ASes with a ratio of less or equal 0.5 are categorized as `Not Validating RPKI ROV`\\n'}, {'organization': 'World Bank', 'name': 'Indicators API: Country Population Indicator', 'url': 'https://www.worldbank.org', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/worldbank#readme', 'reference_name': 'worldbank.country_pop', 'readme_header': \"# World Bank's country population -- https://www.worldbank.org/en/home\\n\\n> The World Bank Group works in every major area of development. We provide a wide array of financial products and technical assistance, and we help countries share and apply innovative knowledge and solutions to the challenges they face.\\n\\n> The World Bank is like a cooperative, made up of 189 member countries. These member countries, or shareholders, are represented by a Board of Governors, who are the ultimate policymakers at the World Bank. Generally, the governors are member countries' ministers of finance or ministers of development. They meet once a year at the Annual Meetings of the Boards of Governors of the World Bank Group and the International Monetary Fund.\\n\"}], tool_call_id='call_8gnx9bue', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 32, 275626, tzinfo=datetime.timezone.utc))], run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0'),\n",
       " ModelResponse(parts=[ThinkingPart(content=\"We need dataset associated to IXPs. Likely PeeringDB ix, ixlan, fac, etc. Also CAIDA ix dataset. Provide modeling description: nodes types for IXP, Facility, LAN, Members etc, relationships. Need to fetch a resource to get readme details for PeeringDB or CAIDA. Let's get peeringdb.\", id='reasoning', provider_name='ollama'), ToolCallPart(tool_name='get_resource', args='{\"uri\":\"dataset://peeringdb.ix\"}', tool_call_id='call_t66otkij')], usage=RequestUsage(input_tokens=16579, output_tokens=101), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 36, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-167', finish_reason='tool_call', run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='get_resource', content={'organization': 'PeeringDB', 'name': 'API endpoint: ix', 'url': 'https://www.peeringdb.com', 'readme_url': 'https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme', 'reference_name': 'peeringdb.ix', 'readme_header': '# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n', 'readme_content': \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\\n## Dependencies\\n\\nRun crawlers in this order:\\n\\n1. org\\n1. fac\\n1. ix\\n\\n## `org.py`\\n\\nInformation about organizations that own networks, IXPs, and facilities.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:Country {country_code})`: Country code\\n- `(:Name {name})`: Name\\n- `(:Organization {name})`: Name\\n- `(:PeeringdbOrgID {id})`: ID\\n- `(:URL {url})`: Website\\n\\nRelationships:\\n\\n```Cypher\\n(:Organization)-[:COUNTRY]->(:Country)\\n(:Organization)-[:EXTERNAL_ID]->(:PeeringdbOrgID)\\n(:Organization)-[:NAME]->(:Name)\\n(:Organization)-[:WEBSITE]->(:URL)\\n```\\n\\nThe `EXTERNAL_ID` relationship contains the raw organization data from PeeringDB [as defined in the\\nAPI.](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20org)\\n\\n## `fac.py`\\n\\nInformation about co-location facilities.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:Country {country_code})`: Country code\\n- `(:Facility {name})`: Name\\n- `(:Name {name})`: Name\\n- `(:PeeringdbFacID {id})`: ID\\n- `(:URL {url})`: Website\\n\\nRelationships:\\n\\n```Cypher\\n(:Facility)-[:COUNTRY]->(:Country)\\n(:Facility)-[:EXTERNAL_ID]->(:PeeringdbFacID)\\n(:Facility)-[:MANAGED_BY]->(:Organization)\\n(:Facility)-[:NAME]->(:Name)\\n(:Facility)-[:WEBSITE]->(:URL)\\n```\\n\\nThe `EXTERNAL_ID` relationship contains the raw facility data from PeeringDB [as defined in the\\nAPI.](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20fac)\\n\\n## `ix.py`\\n\\nInformation about IXPs, peering LANs, and IXP member networks.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:AS {asn})`: ASN of IXP member\\n- `(:IXP {name})`: Name\\n- `(:Name {name})`: Names of IXPs and networks\\n- `(:PeeringdbIXID {id})`: ID of the IXP\\n- `(:PeeringdbNetID {id})`: ID of the network\\n- `(:PeeringLAN {prefix})`: Prefix of IXP peering LAN\\n- `(:URL {url})`: Websites of IXPs and networks\\n\\nRelationships:\\n\\n```Cypher\\n(:IXP)-[:COUNTRY]->(:Country)\\n(:IXP)-[:EXTERNAL_ID]->(:PeeringdbIXID)\\n(:IXP)-[:LOCATED_IN]->(:Facility)\\n(:IXP)-[:MANAGED_BY]->(:Organization)\\n(:IXP)-[:NAME]->(:Name)\\n(:IXP)-[:WEBSITE]->(:URL)\\n\\n(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)\\n(:AS)-[:LOCATED_IN]->(:Facility)\\n(:AS)-[:MANAGED_BY]->(:Organization)\\n(:AS)-[:MEMBER_OF]->(:IXP)\\n(:AS)-[:NAME]->(:Name)\\n(:AS)-[:WEBSITE]->(:URL)\\n\\n(:PeeringLAN)-[:MANAGED_BY]->(:IXP)\\n```\\n\\nRaw data attached to relationships:\\n\\n- [`net`](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20net):\\n  - `(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)`\\n  - `(:AS)-[:MANAGED_BY]->(:Organization)`\\n  - `(:AS)-[:MEMBER_OF]->(:IXP)`\\n  - `(:AS)-[:NAME]->(:Name)`\\n  - `(:AS)-[:WEBSITE]->(:URL)`\\n- [`netfac`](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20netfac):\\n  `(:AS)-[:LOCATED_IN]->(:Facility)`\\n\\n## Example\\n\\nRun the (long) query below to get an Example that contains all nodes and relationships created by\\nthe crawlers.\\n\\n```Cypher\\nMATCH (iij:AS {asn: 2497})-[r0:EXTERNAL_ID]->(n0:PeeringdbNetID)\\nMATCH (iij)-[r1:LOCATED_IN]->(n1:Facility {name: 'IIJ Ikebukuro DC'})\\nMATCH (iij)-[r2:MANAGED_BY]->(n2:Organization)\\nMATCH (iij)-[r3:MEMBER_OF]->(ix:IXP {name: 'DE-CIX Frankfurt'})\\nMATCH (iij)-[r4:NAME {reference_org: 'PeeringDB'}]->(n3:Name)\\nMATCH (iij)-[r5:WEBSITE]->(n4:URL)\\nMATCH (pfx:PeeringLAN {af: 4})-[r6:MANAGED_BY]->(ix)\\nMATCH (ix)-[r7:COUNTRY]->(n5:Country)\\nMATCH (ix)-[r8:EXTERNAL_ID]->(n6:PeeringdbIXID)\\nMATCH (ix)-[r9:LOCATED_IN]->(n7:Facility {name: 'Global Switch Frankfurt'})\\nMATCH (ix)-[r10:MANAGED_BY]->(n8:Organization)\\nMATCH (ix)-[r11:NAME]->(n9:Name)\\nMATCH (ix)-[r12:WEBSITE]->(n10)\\nRETURN iij,ix,pfx,n0,n1,n2,n3,n4,n5,n6,n7,n8,n9,n10,r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12\\n```\\n\\n![Nodes and relationships created by the PeeringDB\\ncrawler](/documentation/assets/gallery/peeringdbAll.svg)\\n\"}, tool_call_id='call_t66otkij', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 36, 338874, tzinfo=datetime.timezone.utc))], run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0'),\n",
       " ModelResponse(parts=[TextPart(content='**IXPs in IYP – the dataset and the data model**\\n\\n---\\n\\n## 1️⃣  Which dataset holds the IXP information?\\n\\nThe Internet Yellow Pages (IYP) gets authoritative IXP data from **PeeringDB**.  \\nThe specific IYP dataset that you can query is:\\n\\n```\\ndataset://peeringdb.ix\\n```\\n\\n(You can also look at the related *fac* and *net* datasets for facilities and member networks.)\\n\\n---\\n\\n## 2️⃣  How are IXPs modeled in the IYP knowledge‑graph?\\n\\nThe PeeringDB crawler creates a rich graph that captures **IXPs, their facilities, LANs, member ASes, organisations and auxiliary data**.  \\nBelow is a concise summary of the node types and the relationships that appear for an IXP.\\n\\n| **Node type** | **Key property** | **What it represents** |\\n|---------------|------------------|------------------------|\\n| `(:IXP)` | `name` | The Internet Exchange Point itself |\\n| `(:Facility)` | `name` | Co‑location/data‑center where the IXP is housed |\\n| `(:Country)` | `country_code` | Country of the IXP (or facility) |\\n| `(:Organization)` | `name` | The legal entity that runs the IXP |\\n| `(:PeeringLAN)` | `prefix` (e.g. `2001:7f8:1::/48`) | The VLAN / prefix used for the IXP’s peering LAN |\\n| `(:AS)` | `asn` | Autonomous System of a member network |\\n| `(:PeeringdbIXID)` | `id` | Raw PeeringDB identifier for the IXP |\\n| `(:PeeringdbFacID)` | `id` | Raw PeeringDB identifier for a facility |\\n| `(:PeeringdbNetID)` | `id` | Raw PeeringDB identifier for a member network |\\n| `(:Name)` | `name` | Human‑readable names (IXP name, facility name, AS name) |\\n| `(:URL)` | `url` | Web site of the IXP, facility or member network |\\n\\n### Core relationships\\n\\n```cypher\\n(:IXP)-[:COUNTRY]->(:Country)                // where the IXP is located\\n(:IXP)-[:EXTERNAL_ID]->(:PeeringdbIXID)      // raw PeeringDB record\\n(:IXP)-[:LOCATED_IN]->(:Facility)            // data‑center that hosts it\\n(:IXP)-[:MANAGED_BY]->(:Organization)        // owning organisation\\n(:IXP)-[:NAME]->(:Name)                      // IXP name node\\n(:IXP)-[:WEBSITE]->(:URL)                    // IXP website\\n\\n(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)      // raw PeeringDB net record\\n(:AS)-[:LOCATED_IN]->(:Facility)             // member’s presence in a facility\\n(:AS)-[:MANAGED_BY]->(:Organization)         // member operator\\n(:AS)-[:MEMBER_OF]->(:IXP)                   // AS is a member of this IXP\\n(:AS)-[:NAME]->(:Name)                       // AS name\\n(:AS)-[:WEBSITE]->(:URL)                     // member’s website\\n\\n(:PeeringLAN)-[:MANAGED_BY]->(:IXP)          // LAN belongs to the IXP\\n```\\n\\n*Additional relationship properties* (e.g., raw JSON blobs) are attached to the `EXTERNAL_ID` edges – they hold the full API payload from PeeringDB for later inspection.\\n\\n### Example query (from the documentation)\\n\\n```cypher\\nMATCH (as:AS {asn: 2497})-[r0:EXTERNAL_ID]->(n0:PeeringdbNetID)\\nMATCH (as)-[r1:LOCATED_IN]->(fac:Facility {name:\\'IIJ Ikebukuro DC\\'})\\nMATCH (as)-[r2:MANAGED_BY]->(org:Organization)\\nMATCH (as)-[r3:MEMBER_OF]->(ix:IXP {name:\\'DE-CIX Frankfurt\\'})\\nMATCH (as)-[r4:NAME]->(n3:Name)\\nMATCH (as)-[r5:WEBSITE]->(n4:URL)\\nMATCH (pfx:PeeringLAN {af:4})-[r6:MANAGED_BY]->(ix)\\nMATCH (ix)-[r7:COUNTRY]->(c:Country)\\nMATCH (ix)-[r8:EXTERNAL_ID]->(ixid:PeeringdbIXID)\\nMATCH (ix)-[r9:LOCATED_IN]->(fac2:Facility {name:\\'Global Switch Frankfurt\\'})\\nMATCH (ix)-[r10:MANAGED_BY]->(org2:Organization)\\nMATCH (ix)-[r11:NAME]->(n9:Name)\\nMATCH (ix)-[r12:WEBSITE]->(n10:URL)\\nRETURN as, ix, pfx,\\n       n0,n1,n2,n3,n4,n5,n6,n7,n8,n9,n10,\\n       r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12;\\n```\\n\\nThe visualisation produced by this query is the **full IXP sub‑graph** (IXP, its facility, country, member ASes, LAN, etc.).\\n\\n---\\n\\n## 3️⃣  Quick way to explore the data\\n\\nIf you have access to the IYP GraphQL/Neo4j endpoint, you can run a short query to list all IXPs:\\n\\n```cypher\\nMATCH (i:IXP) RETURN i.name AS ixp_name, i.id AS ixp_id, i.country_code AS country\\nORDER BY ixp_name;\\n```\\n\\nOr to see a specific IXP’s members:\\n\\n```cypher\\nMATCH (i:IXP {name:\"DE-CIX Frankfurt\"})<-[:MEMBER_OF]-(m:AS)\\nRETURN m.asn AS member_asn, m.name AS member_name\\nORDER BY m.asn;\\n```\\n\\n---\\n\\n### TL;DR\\n\\n* **Dataset** – `peeringdb.ix` (PeeringDB’s IXP API data).  \\n* **Model** – IXP → Country, Facility, Organization, PeeringLAN, Member ASes, each with explicit `EXTERNAL_ID` nodes for the raw PeeringDB payload and `NAME`/`URL` auxiliary nodes.  \\n* **Graph shape** – Rich, typed nodes with clear relationships (`MEMBER_OF`, `LOCATED_IN`, `MANAGED_BY`, `MANAGED_BY` for LANs, etc.), enabling easy traversal from an IXP to its members, location, and underlying data‑center.  \\n\\nYou can now query or visualise IXPs directly in IYP using the above model. Happy exploring!')], usage=RequestUsage(input_tokens=18292, output_tokens=1433), model_name='gpt-oss:120b', timestamp=datetime.datetime(2025, 11, 21, 10, 12, 58, tzinfo=TzInfo(0)), provider_name='ollama', provider_details={'finish_reason': 'stop'}, provider_response_id='chatcmpl-721', finish_reason='stop', run_id='2d8c9135-3f77-424a-b1f7-0947180f01c0')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f986082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: list[Any], verbose: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Pretty print a list of Pydantic AI messages.\n",
    "\n",
    "    Args:\n",
    "        messages: List of ModelRequest and ModelResponse objects\n",
    "        verbose: If True, show additional metadata like timestamps, usage, etc.\n",
    "    \"\"\"\n",
    "    for i, msg in enumerate(messages):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Message {i + 1}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        # Determine message type\n",
    "        if hasattr(msg, \"kind\"):\n",
    "            if msg.kind == \"request\":\n",
    "                _print_request(msg, verbose)\n",
    "            elif msg.kind == \"response\":\n",
    "                _print_response(msg, verbose)\n",
    "        else:\n",
    "            print(f\"Unknown message type: {type(msg)}\")\n",
    "\n",
    "\n",
    "def _print_request(msg: Any, verbose: bool) -> None:\n",
    "    \"\"\"Print a ModelRequest message.\"\"\"\n",
    "    print(\"📤 REQUEST\")\n",
    "\n",
    "    if verbose and hasattr(msg, \"instructions\") and msg.instructions:\n",
    "        print(f\"\\nInstructions: {msg.instructions}\")\n",
    "\n",
    "    print(\"\\nParts:\")\n",
    "    for j, part in enumerate(msg.parts):\n",
    "        _print_request_part(part, j, verbose)\n",
    "\n",
    "\n",
    "def _print_response(msg: Any, verbose: bool) -> None:\n",
    "    \"\"\"Print a ModelResponse message.\"\"\"\n",
    "    print(\"📥 RESPONSE\")\n",
    "\n",
    "    if verbose:\n",
    "        if hasattr(msg, \"model_name\") and msg.model_name:\n",
    "            print(f\"Model: {msg.model_name}\")\n",
    "        if hasattr(msg, \"provider_name\") and msg.provider_name:\n",
    "            print(f\"Provider: {msg.provider_name}\")\n",
    "        if hasattr(msg, \"timestamp\"):\n",
    "            print(f\"Timestamp: {msg.timestamp}\")\n",
    "        if hasattr(msg, \"usage\"):\n",
    "            print(f\"Usage: {msg.usage}\")\n",
    "        if hasattr(msg, \"provider_request_id\") and msg.provider_request_id:\n",
    "            print(f\"Request ID: {msg.provider_request_id}\")\n",
    "        if hasattr(msg, \"provider_details\") and msg.provider_details:\n",
    "            print(f\"Provider Details: {msg.provider_details}\")\n",
    "        if hasattr(msg, \"finish_reason\") and msg.finish_reason:\n",
    "            print(f\"Finish Reason: {msg.finish_reason}\")\n",
    "\n",
    "    print(\"\\nParts:\")\n",
    "    for j, part in enumerate(msg.parts):\n",
    "        _print_response_part(part, j, verbose)\n",
    "\n",
    "\n",
    "def _print_request_part(part: Any, index: int, verbose: bool) -> None:\n",
    "    \"\"\"Print a single ModelRequestPart.\"\"\"\n",
    "    part_kind = getattr(part, \"part_kind\", \"unknown\")\n",
    "\n",
    "    print(f\"\\n  [{index}] {_get_part_icon(part_kind)} {part_kind.upper()}\")\n",
    "\n",
    "    if part_kind == \"system-prompt\":\n",
    "        print(f\"      Content: {_truncate(part.content, 500)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"dynamic_ref\") and part.dynamic_ref:\n",
    "                print(f\"      Dynamic Ref: {part.dynamic_ref}\")\n",
    "\n",
    "    elif part_kind == \"user-prompt\":\n",
    "        content = part.content\n",
    "        if isinstance(content, str):\n",
    "            print(f\"      Content: {_truncate(content, 500)}\")\n",
    "        elif isinstance(content, list):\n",
    "            print(f\"      Content (multipart):\")\n",
    "            for item in content:\n",
    "                _print_content_item(item)\n",
    "        if verbose and hasattr(part, \"timestamp\"):\n",
    "            print(f\"      Timestamp: {part.timestamp}\")\n",
    "\n",
    "    elif part_kind == \"tool-return\":\n",
    "        print(f\"      Tool: {part.tool_name}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        print(f\"      Content: {_format_json(part.content, indent=8)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"metadata\") and part.metadata:\n",
    "                print(f\"      Metadata: {part.metadata}\")\n",
    "\n",
    "    elif part_kind == \"retry-prompt\":\n",
    "        print(f\"      Tool: {part.tool_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id or 'N/A'}\")\n",
    "        if isinstance(part.content, str):\n",
    "            print(f\"      Content: {_truncate(part.content, 500)}\")\n",
    "        else:\n",
    "            print(f\"      Content (errors): {len(part.content)} validation errors\")\n",
    "            if verbose:\n",
    "                for error in part.content[:3]:  # Show first 3 errors\n",
    "                    print(f\"        - {error}\")\n",
    "        if verbose and hasattr(part, \"timestamp\"):\n",
    "            print(f\"      Timestamp: {part.timestamp}\")\n",
    "\n",
    "\n",
    "def _print_response_part(part: Any, index: int, verbose: bool) -> None:\n",
    "    \"\"\"Print a single ModelResponsePart.\"\"\"\n",
    "    part_kind = getattr(part, \"part_kind\", \"unknown\")\n",
    "\n",
    "    print(f\"\\n  [{index}] {_get_part_icon(part_kind)} {part_kind.upper()}\")\n",
    "\n",
    "    if part_kind == \"text\":\n",
    "        print(f\"      Content: {_truncate(part.content, 500)}\")\n",
    "\n",
    "    elif part_kind == \"thinking\":\n",
    "        print(f\"      Content: {_truncate(part.content, 500)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"id\") and part.id:\n",
    "                print(f\"      ID: {part.id}\")\n",
    "            if hasattr(part, \"signature\") and part.signature:\n",
    "                print(f\"      Signature: {part.signature}\")\n",
    "\n",
    "    elif part_kind == \"tool-call\":\n",
    "        print(f\"      Tool: {part.tool_name}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        args = part.args\n",
    "        if isinstance(args, str):\n",
    "            print(f\"      Args (JSON): {_truncate(args, 300)}\")\n",
    "        else:\n",
    "            print(f\"      Args: {_format_json(args, indent=8)}\")\n",
    "\n",
    "    elif part_kind == \"builtin-tool-call\":\n",
    "        print(f\"      Tool: {part.tool_name} (builtin)\")\n",
    "        print(f\"      Provider: {part.provider_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        args = part.args\n",
    "        if isinstance(args, str):\n",
    "            print(f\"      Args (JSON): {_truncate(args, 300)}\")\n",
    "        else:\n",
    "            print(f\"      Args: {_format_json(args, indent=8)}\")\n",
    "\n",
    "    elif part_kind == \"builtin-tool-return\":\n",
    "        print(f\"      Tool: {part.tool_name} (builtin)\")\n",
    "        print(f\"      Provider: {part.provider_name or 'N/A'}\")\n",
    "        print(f\"      Tool Call ID: {part.tool_call_id}\")\n",
    "        print(f\"      Content: {_format_json(part.content, indent=8)}\")\n",
    "        if verbose:\n",
    "            if hasattr(part, \"timestamp\"):\n",
    "                print(f\"      Timestamp: {part.timestamp}\")\n",
    "            if hasattr(part, \"metadata\") and part.metadata:\n",
    "                print(f\"      Metadata: {part.metadata}\")\n",
    "\n",
    "\n",
    "def _print_content_item(item: Any) -> None:\n",
    "    \"\"\"Print a content item from multipart user prompt.\"\"\"\n",
    "    if isinstance(item, str):\n",
    "        print(f\"        - Text: {_truncate(item, 200)}\")\n",
    "    elif hasattr(item, \"kind\"):\n",
    "        kind = item.kind\n",
    "        if kind == \"image-url\":\n",
    "            print(f\"        - Image URL: {item.url}\")\n",
    "        elif kind == \"video-url\":\n",
    "            print(f\"        - Video URL: {item.url}\")\n",
    "        elif kind == \"audio-url\":\n",
    "            print(f\"        - Audio URL: {item.url}\")\n",
    "        elif kind == \"document-url\":\n",
    "            print(f\"        - Document URL: {item.url}\")\n",
    "        elif kind == \"binary\":\n",
    "            media = item.media_type\n",
    "            size = len(item.data) if hasattr(item, \"data\") else 0\n",
    "            print(f\"        - Binary: {media} ({size} bytes)\")\n",
    "    elif hasattr(item, \"type\"):\n",
    "        print(f\"        - {item.type}: {item}\")\n",
    "    else:\n",
    "        print(f\"        - Unknown: {type(item)}\")\n",
    "\n",
    "\n",
    "def _get_part_icon(part_kind: str) -> str:\n",
    "    \"\"\"Get an emoji icon for the part kind.\"\"\"\n",
    "    icons = {\n",
    "        \"system-prompt\": \"⚙️\",\n",
    "        \"user-prompt\": \"👤\",\n",
    "        \"tool-return\": \"🔧\",\n",
    "        \"retry-prompt\": \"🔄\",\n",
    "        \"text\": \"💬\",\n",
    "        \"thinking\": \"🤔\",\n",
    "        \"tool-call\": \"🛠️\",\n",
    "        \"builtin-tool-call\": \"🏗️\",\n",
    "        \"builtin-tool-return\": \"🏗️\",\n",
    "    }\n",
    "    return icons.get(part_kind, \"❓\")\n",
    "\n",
    "\n",
    "def _truncate(text: str, max_length: int = 500) -> str:\n",
    "    \"\"\"Truncate text to a maximum length.\"\"\"\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    return text[:max_length] + \"...\"\n",
    "\n",
    "\n",
    "def _format_json(obj: Any, indent: int = 0) -> str:\n",
    "    \"\"\"Format an object as JSON with proper indentation.\"\"\"\n",
    "    if obj is None:\n",
    "        return \"null\"\n",
    "\n",
    "    try:\n",
    "        if isinstance(obj, str):\n",
    "            # Try to parse as JSON if it's a string\n",
    "            try:\n",
    "                parsed = json.loads(obj)\n",
    "                return json.dumps(parsed, indent=2).replace(\"\\n\", \"\\n\" + \" \" * indent)\n",
    "            except:\n",
    "                return obj\n",
    "        else:\n",
    "            return json.dumps(obj, indent=2, default=str).replace(\n",
    "                \"\\n\", \"\\n\" + \" \" * indent\n",
    "            )\n",
    "    except:\n",
    "        return str(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14cda3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Message 1\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] ⚙️ SYSTEM-PROMPT\n",
      "      Content: You are a helpful assistant providing information based one the Internet Yellow Pages (IYP, a knowdledge graph about the Internet) documentation.\n",
      "Use available tools to retrieve informations. Always assume the answer to the user request is in the documentation (it's your job to find it)\n",
      "\n",
      "  [1] 👤 USER-PROMPT\n",
      "      Content: Find the dataset associated to IXPs and show me how IXPs are modeled in IYP\n",
      "\n",
      "================================================================================\n",
      "Message 2\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🤔 THINKING\n",
      "      Content: We need to find dataset associated to IXPs and then describe modeling of IXPs in IYP. Use list_datasets then get_resource for dataset about IXPs. Let's list datasets.\n",
      "\n",
      "  [1] 🛠️ TOOL-CALL\n",
      "      Tool: list_datasets\n",
      "      Tool Call ID: call_8gnx9bue\n",
      "      Args (JSON): {}\n",
      "\n",
      "================================================================================\n",
      "Message 3\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🔧 TOOL-RETURN\n",
      "      Tool: list_datasets\n",
      "      Tool Call ID: call_8gnx9bue\n",
      "      Content: [\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"IXP route server looking glass snapshots\",\n",
      "            \"url\": \"https://github.com/alice-lg/alice-lg\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": null,\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"AMS-IX\",\n",
      "            \"url\": \"https://lg.ams-ix.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.amsix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"BCIX\",\n",
      "            \"url\": \"https://lg.bcix.de\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.bcix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"DE-CIX\",\n",
      "            \"url\": \"https://lg.de-cix.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.decix\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"IX.br\",\n",
      "            \"url\": \"https://lg.ix.br\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.ixbr\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"LINX\",\n",
      "            \"url\": \"https://alice-rs.linx.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.linx\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"Megaport\",\n",
      "            \"url\": \"https://lg.megaport.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.megaport\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Alice-LG\",\n",
      "            \"name\": \"Netnod\",\n",
      "            \"url\": \"https://lg.netnod.se\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/alice_lg#readme\",\n",
      "            \"reference_name\": \"alice_lg.netnod\",\n",
      "            \"readme_header\": \"# Alice-LG -- https://github.com/alice-lg/alice-lg\\n\\nAlice-LG is a BGP looking glass which gets its data from external APIs.\\n\\nIt is used by some large IXPs (e.g., DE-CIX, LINX, AMS-IX) and IYP imports membership\\ninformation by reading the route server neighbors.\\n\\nThe crawler *can* also import the received routes of all neighbors, however testing has\\nshown that this takes an unreasonable amount of time for most IXPs due to the tiny\\npagination size (250 routes per page). Therefore this functionality is disabled by default.\\n\\nList of supported IXPs:\\n\\n- AMS-IX (`amsix.py`)\\n- BCIX (`bcix.py`)\\n- DE-CIX (`decix.py`)\\n- IX.br (`ixbr.py`)\\n- LINX (`linx.py`)\\n- Megaport (`megaport.py`)\\n- Netnod (`netnod.py`)\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"APNIC\",\n",
      "            \"name\": \"AS population estimate\",\n",
      "            \"url\": \"https://stats.labs.apnic.net/aspop\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/apnic#readme\",\n",
      "            \"reference_name\": \"apnic.eyeball\",\n",
      "            \"readme_header\": \"# APNIC population estimates -- https://labs.apnic.net/\\n\\nPopulation per AS estimated using an advertisement on Youtube. This dataset \\nprovides:\\n- the percentage of the population per country/AS\\n- AS ranking in terms of population\\n- AS names\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"as2rel\",\n",
      "            \"url\": \"https://data.bgpkit.com/as2rel\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.as2rel_v4, bgpkit.as2rel_v6\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"peer-stats\",\n",
      "            \"url\": \"https://data.bgpkit.com/peer-stats\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.peerstats\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"BGPKIT\",\n",
      "            \"name\": \"pfx2as\",\n",
      "            \"url\": \"https://data.bgpkit.com/pfx2as\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgpkit#readme\",\n",
      "            \"reference_name\": \"bgpkit.pfx2asn\",\n",
      "            \"readme_header\": \"# BGPKIT data -- https://data.bgpkit.com\\n\\nData inferred from RouteViews and RIPE RIS BGP data, including:\\n- AS relationship\\n- prefix to ASN mappings\\n- BGP collectors' peers stats\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"Anycast prefix tags\",\n",
      "            \"url\": \"https://github.com/bgptools/anycast-prefixes\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.anycast_prefixes\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://bgp.tools/kb/api\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.as_names\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"bgp.tools\",\n",
      "            \"name\": \"AS tags\",\n",
      "            \"url\": \"https://bgp.tools/kb/api\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/bgptools#readme\",\n",
      "            \"reference_name\": \"bgptools.tags\",\n",
      "            \"readme_header\": \"# bgp.tools -- https://bgp.tools\\n\\nData collected by bgp.tools, including:\\n\\n- AS names\\n- AS tags\\n- Anycast IPv4 and IPv6 prefixes\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS to Organizations\",\n",
      "            \"url\": \"https://catalog.caida.org/dataset/as_organizations\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.as2org\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS Rank\",\n",
      "            \"url\": \"https://doi.org/10.21986/CAIDA.DATA.AS-RANK\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.asrank\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"AS Relationships\",\n",
      "            \"url\": \"https://catalog.caida.org/dataset/as_relationships_serial_1\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.as_relationships_v4, caida.as_relationships_v6\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"CAIDA\",\n",
      "            \"name\": \"IXPs Dataset\",\n",
      "            \"url\": \"https://doi.org/10.21986/CAIDA.DATA.IXPS\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/caida#readme\",\n",
      "            \"reference_name\": \"caida.ixs, caida.ix_asns\",\n",
      "            \"readme_header\": \"# CAIDA -- https://caida.org\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cisco\",\n",
      "            \"name\": \"Umbrella Popularity List\",\n",
      "            \"url\": \"https://s3-us-west-1.amazonaws.com/umbrella-static/index.html\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco#readme\",\n",
      "            \"reference_name\": \"cisco.umbrella_top1m\",\n",
      "            \"readme_header\": \"# Cisco Umbrella -- https://umbrella-static.s3-us-west-1.amazonaws.com/index.html\\n\\nThe popularity list contains most queried domains (ranging from TLDs to FQDNs)\\nbased on passive DNS usage across the Umbrella global network.\\n\\nIYP uses this data to create and annotate DomainName and HostName nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Citizen Lab\",\n",
      "            \"name\": \"URL testing lists\",\n",
      "            \"url\": \"https://github.com/citizenlab/test-lists\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/citizenlab#readme\",\n",
      "            \"reference_name\": \"citizenlab.urldb\",\n",
      "            \"readme_header\": \"# Citizen Lab -- https://github.com/citizenlab/test-lists/blob/master/lists/\\n\\nCitizen lab's test lists are URL testing lists intended to help in testing URL censorship, divided by country codes. In addition to these local lists, the global list consists of a wide range of internationally relevant and popular websites, including sites with content that is perceived to be provocative or objectionable. The dataset tha maps URL to Category.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/datasets\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.ranking_bucket\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/dns/top/ases\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.dns_top_ases\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/dns/top/locations\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.dns_top_locations\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Cloudflare\",\n",
      "            \"name\": \"Cloudflare Radar API endpoint radar/ranking/top (top 100 domain names)\",\n",
      "            \"url\": \"https://radar.cloudflare.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cloudflare#readme\",\n",
      "            \"reference_name\": \"cloudflare.top100\",\n",
      "            \"readme_header\": \"# Cloudflare Radar -- https://radar.cloudflare.com/\\n\\nCloudflare uses aggregated and anonymized DNS queries to their `1.1.1.1` public resolver service to\\nprovide various datasets, including:\\n\\n- [Ordered top 100 domain\\n  names](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): The 100\\n  domains with the most DNS queries, including assigned ranks.\\n- [Unordered top 1,000 to 1,000,000\\n  domains](https://developers.cloudflare.com/radar/investigate/domain-ranking-datasets/): Same as\\n  above, but there are no ranks assigned. Fetched set sizes are 1,000, 2,000, 5,000, 10,000, 20,000,\\n  50,000, 100,000, 200,000, 500,000, and 1,000,000.\\n- [Top 100 countries querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/radar/investigate/dns/#top-locations): For each domain\\n  that is in the top 10,000 of *any* ranking included in IYP, fetch the top 100 countries with the\\n  most DNS queries.\\n- [Top 100 ASes querying each of the 10,000 highest ranked domain\\n  names](https://developers.cloudflare.com/api/operations/radar-get-dns-top-ases): Same as above, but\\n  fetch AS numbers instead.\\n\\nAll rankings are based on one week of data.\\nCloudflare radar's top location and ASes is available for both domain names\\nand host names. Results are likely accounting for all NS, A, AAAA queries made to\\nCloudflare's resolver. Since NS queries for host names make no sense IYP links these\\nresults to `DomainName` nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Emile Aben\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://github.com/emileaben/asnames\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/emileaben#readme\",\n",
      "            \"reference_name\": \"emileaben.as_names\",\n",
      "            \"readme_header\": \"# EmileAben's AS Names -- https://github.com/emileaben/asnames\\n\\nData collected by EmileAben's AS Names, including:\\n\\n- AS numbers\\n- AS names\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Google\",\n",
      "            \"name\": \"CrUX top 1M websites per country\",\n",
      "            \"url\": \"https://developer.chrome.com/docs/crux\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/google#readme\",\n",
      "            \"reference_name\": \"google.crux_top1m_country\",\n",
      "            \"readme_header\": \"# Google CrUX -- https://developer.chrome.com/docs/crux\\n\\nThe Chrome User Experience Report (CrUX for short) is a dataset collected by\\nGoogle that reflects how real-world Chrome users experience popular\\ndestinations on the web.\\n\\nCrUX data is collected from real browsers around the world, based on certain\\nbrowser options which determine user eligibility. A set of dimensions and metrics\\nare collected which allow site owners to determine how users experience their sites.\\n\\nIYP fetches CrUX's [top 1M popular websites per country](https://github.com/InternetHealthReport/crux-top-lists-country).\\nUnlike others, CrUX rankings are bucketed by rank magnitude order, not by\\nspecific rank. For example, ranks are 1000, 10k, 100k, or 1M.\\n\\nIn addition, CrUX ranks *origins* (e.g., https://www.google.com), not domain\\nor host names. In IYP we extract the hostname part of the origin and model this\\ndataset using the hostname.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"AS Hegemony\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#AS-dependency\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.local_hegemony_v4, ihr.local_hegemony_v6\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"Country Dependency\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#Country-s-network-dependency\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.country_dependency\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IHR\",\n",
      "            \"name\": \"ROV\",\n",
      "            \"url\": \"https://www.ihr.live/en/documentation#Route-Origin-Validation\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ihr#readme\",\n",
      "            \"reference_name\": \"ihr.rov\",\n",
      "            \"readme_header\": \"# Internet Health Report -- https://ihr.iijlab.net/\\n\\nData inferred by IIJ's Internet Health Report, including:\\n\\n- AS inter-dependency\\n- country's AS dependency\\n- prefixes' RPKI and IRR status\\n\\n#### Country's AS dependency\\nThe way to retrieve the country AS dependency values shown on IHR website (e.g. https://ihr.iijlab.net/ihr/en-us/countries/JP) is as follow.\\nFor eyeball ranking nodes get `hege` and `weight` values from the corresponding RANK relationship and then:\\n- Population Total = 100*`hege`\\n- Population Direct = `weight`\\n- Population Indirect = 100*`hege`-`weight`\\n\\nFor AS ranking nodes get `hege` values from the corresponding RANK relationship and then:\\n- AS Total = 100*`hege`\\n\\nThe values are not exactly the same as the ones shown on the IHR website because the IHR website averages results over three days.\\n\\n\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Internet Intelligence Lab\",\n",
      "            \"name\": \"AS to Organization Mapping\",\n",
      "            \"url\": \"https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/inetintel#readme\",\n",
      "            \"reference_name\": \"inetintel.as_org\",\n",
      "            \"readme_header\": \"# Internet Intelligence Lab - Dataset: AS to Organization mapping -- https://github.com/InetIntel/Dataset-AS-to-Organization-Mapping\\n\\nThe dataset contains historical and current versions of the AS to Organization \\nmapping datasets. A mapping will be created between AS to its sibling ASes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"IPinfo\",\n",
      "            \"name\": \"IP to Country Mapping\",\n",
      "            \"url\": \"https://ipinfo.io\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ipinfo#readme\",\n",
      "            \"reference_name\": \"ipinfo.ip_country\",\n",
      "            \"readme_header\": \"# IPinfo -- https://ipinfo.io/\\n\\nIPinfo is an IP geolocation service, that provides different kinds of IP databases,\\nincluding a [free tier](https://ipinfo.io/products/free-ip-database) that maps IP ranges\\nto countries. We import the free database into IYP.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"NRO\",\n",
      "            \"name\": \"Extended allocation and assignment reports\",\n",
      "            \"url\": \"https://www.nro.net/about/rirs/statistics\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/nro#readme\",\n",
      "            \"reference_name\": \"nro.delegated_stats\",\n",
      "            \"readme_header\": \"# Number Resource Organization -- https://www.nro.net/\\n\\nThe Number Resource Organization (NRO) is the coordinating body for the world\\u2019s Regional Internet\\nRegistries (RIRs). The RIRs manage the distribution of Internet number resources (IP address space\\nand Autonomous System Numbers) within their respective regions.\\n\\nAs part of a joint RIR project to provide consistent and accessible Internet number resource\\nstatistics the NRO publishes [*Extended Allocation and Assignment\\nReports*](https://www.nro.net/about/rirs/statistics/) (also called *delegated stats*) that contain\\ninformation about assigned IP address ranges and AS numbers.\\n\\nEach line of the report is a record that either represents an IP address range or an AS number. The\\nrecord has a status and maps to an *opaque ID* that uniquely identifies a single organization.\\nFinally, the record contains a country code to which the organization belongs.\\n\\n**Note:** If the record is not assigned, the country code is `ZZ`, which will still be inserted into\\nIYP.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Facebook Messenger\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-019-facebook-messenger.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.facebookmessenger\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Header Field Manipulation Test\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-006-header-field-manipulation.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.httpheaderfieldmanipulation\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"HTTP Invalid Request Line Test\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-007-http-invalid-request-line.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.httpinvalidrequestline\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Signal\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-029-signal.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.osignal\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Psiphon\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-015-psiphon.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.psiphon\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"RiseupVPN\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-026-riseupvpn.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.riseupvpn\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"STUN reachability\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-025-stun-reachability.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.stunreachability\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Telegram\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-020-telegram.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.telegram\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Tor\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-023-tor.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.tor\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Tor using snowflake\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-030-torsf.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.torsf\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Vanilla Tor\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-016-vanilla-tor.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.vanillator\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"Web Connectivity\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-017-web-connectivity.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.webconnectivity\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OONI\",\n",
      "            \"name\": \"WhatsApp\",\n",
      "            \"url\": \"https://github.com/ooni/spec/blob/master/nettests/ts-018-whatsapp.md\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ooni#readme\",\n",
      "            \"reference_name\": \"ooni.whatsapp\",\n",
      "            \"readme_header\": \"# OONI -- https://ooni.org/\\n\\nThe [Open Observatory of Network Interference](https://ooni.org/) (OONI) is a non-profit\\nfree software project that aims to empower decentralized efforts in documenting internet\\ncensorship around the world.  OONI runs a number of tests from devices provided by\\nvolunteers, and we import a subset of these into IYP.\\n\\nSince most of these crawlers create the same graph representation, we first briefly\\ndescribe the function of all tests and link to their detailed test specification. Then\\nwe give one combined description of the graph representation at the end.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Google CrUX\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.crux\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Infrastructure\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/infrastructure/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.infra_ns\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Tranco Top 1M\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.tranco1m\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"Cisco Umbrella Top 1M\",\n",
      "            \"url\": \"https://openintel.nl/data/forward-dns/top-lists/\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.umbrella1m\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"OpenINTEL\",\n",
      "            \"name\": \"DNS Dependency Graph\",\n",
      "            \"url\": \"https://dnsgraph.dacs.utwente.nl\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/openintel#readme\",\n",
      "            \"reference_name\": \"openintel.dnsgraph_nl, openintel.dnsgraph_rdns\",\n",
      "            \"readme_header\": \"# OpenINTEL -- https://www.openintel.nl/\\n\\nThe OpenINTEL project captures daily snapshots of the state of large parts of the global\\nDomain Name System (DNS) by running a number of forward and reverse DNS measurements.\\n\\nCurrently, IYP imports three open [toplist-based\\ndatasets](https://openintel.nl/data/forward-dns/top-lists/) and one closed\\n[infrastructure dataset](https://openintel.nl/data/forward-dns/infrastructure/) with\\nkind permission:\\n\\n- Google CRuX: `crux.py` (see also\\n  [google.crux_top1m_country](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/google))\\n- Tranco Top 1M: `tranco1m.py` (see also\\n  [tranco.top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco))\\n- Cisco Umbrella Top 1M: `umbrella1m.py` (see also\\n  [cisco.umbrella_top1m](https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/cisco))\\n- Infrastructure: `infra_ns.py`\\n\\nThe list-based datasets contain results for 12 different types of DNS queries, however\\nwe only import the results of A, AAAA, and NS queries. The toplist datasets yield the\\nname resolution for popular domains as well as the responsible authoritative name\\nservers. The infrastructure dataset performs additional A/AAAA queries for the names of\\nauthoritative name servers observed on the list-based measurements. We also model CNAME\\nrecords that are retrieved as part of the name resolution.\\n\\nA crawler that imports MX records and their corresponding resolution is implemented as\\nwell, but currently not in use (`infra_mx.py`).\\n\\nIYP also imports three datasets of the related [DNS Dependency\\nGraph](https://dnsgraph.dacs.utwente.nl) measurement. This measurement performs name\\nresolution of various host names but records the entire DNS tree, starting at the root,\\nthat is required to resolve the name.\\n\\nThe datasets resolve different host names from different vantage points:\\n\\n- `dnsgraph_crux.py`: Google CRuX hosts measured from Japan.\\n- `dnsgraph_jp.py` (inactive): Tranco Top 1M hosts from Japan.\\n- `dnsgraph_nl.py`: Tranco Top 1M hosts from the Netherlands.\\n- `dnsgraph_rdns.py`: Authoritative name servers managing rDNS zones from the\\n  Netherlands (see also\\n  [simulamet.rirdata_rdns](https://github.com/InternetHealthReport/internet-yellow-pages/blob/main/iyp/crawlers/simulamet)).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Packet Clearing House\",\n",
      "            \"name\": \"Daily routing snapshots\",\n",
      "            \"url\": \"https://www.pch.net/resources/Routing_Data\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/pch#readme\",\n",
      "            \"reference_name\": \"pch.daily_routing_snapshots_v4, pch.daily_routing_snapshots_v6\",\n",
      "            \"readme_header\": \"# Packet Clearing House -- https://www.pch.net/\\n\\nPacket Clearing House (PCH) is an international organization responsible for providing operational\\nsupport and security to critical Internet infrastructure, including Internet exchange points and the\\ncore of the domain name system.\\n\\nPCH operates route collectors at more than 100 Internet Exchange Points around the world.\\n[Data](https://www.pch.net/resources/Routing_Data/) from these route collectors is made available\\npublicly for the benefit of the Internet's operational and research communities.\\n\\nIYP fetches the *Daily snapshots of the results of \\\"show ip bgp\\\" on PCH route collectors*, which\\nindicate the state of the routing table on PCH route collectors at the moment in time that the\\nsnapshot is taken.\\n\\nIYP uses the announced routes to infer the origin ASes of announced prefixes, some of which might\\nnot be visible in route collectors from Route Views or RIPE RIS.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: fac\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.fac\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: ix\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.ix\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: ixlan\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.ixlan\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: netfac\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.netfac\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"PeeringDB\",\n",
      "            \"name\": \"API endpoint: org\",\n",
      "            \"url\": \"https://www.peeringdb.com\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "            \"reference_name\": \"peeringdb.org\",\n",
      "            \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"AS names\",\n",
      "            \"url\": \"https://ftp.ripe.net/ripe/asnames\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.as_names\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RPKI\",\n",
      "            \"url\": \"https://ftp.ripe.net/ripe/rpki\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.roa\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RIPE Atlas measurement information\",\n",
      "            \"url\": \"https://atlas.ripe.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.atlas_measurements\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"RIPE NCC\",\n",
      "            \"name\": \"RIPE Atlas probes\",\n",
      "            \"url\": \"https://atlas.ripe.net\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/ripe#readme\",\n",
      "            \"reference_name\": \"ripe.atlas_probes\",\n",
      "            \"readme_header\": \"# RIPE NCC -- https://www.ripe.net/\\n\\nThe RIPE Network Coordination Centre (RIPE NCC) is the Regional Internet Registry (RIR) for Europe,\\nthe Middle East and parts of Central Asia.\\n\\nIYP does not use RIPE-specific information, but fetches data from RIPE\\u2018s convenient [FTP\\nserver](https://ftp.ripe.net/).\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"SimulaMet\",\n",
      "            \"name\": \"rDNS data\",\n",
      "            \"url\": \"https://rir-data.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/simulamet#readme\",\n",
      "            \"reference_name\": \"simulamet.rirdata_rdns\",\n",
      "            \"readme_header\": \"# rDNS RIR data -- https://rir-data.org/\\n\\n\\\"Lowering the Barriers to Working with Public RIR-Level Data\\\" is a joint project of\\nSimulaMet and the University of Twente with the goal of making WHOIS, route object\\ndelegation, and reverse DNS (rDNS) zone files published by Regional Internet Registries\\n(RIRs) more accessible.\\n\\nIYP imports the rDNS files in a simplified format to indicate which authoritative name\\nservers are responsible for a prefix. We do not model PTR records and the corresponding\\nhierarchy but instead add a simple MANAGED_BY link.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Stanford\",\n",
      "            \"name\": \"ASdb dataset\",\n",
      "            \"url\": \"https://asdb.stanford.edu\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/stanford#readme\",\n",
      "            \"reference_name\": \"stanford.asdb\",\n",
      "            \"readme_header\": \"# Stanford's ASdb -- https://asdb.stanford.edu/\\n\\nASdb is a research dataset that maps public autonomous systems (identified by \\nASN) to organizations and up to three industry types using data from business \\nintelligence databases, website classifiers, and a machine learning algorithm. \\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Tranco\",\n",
      "            \"name\": \"Tranco list\",\n",
      "            \"url\": \"https://tranco-list.eu\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/tranco#readme\",\n",
      "            \"reference_name\": \"tranco.top1m\",\n",
      "            \"readme_header\": \"# Tranco -- https://tranco-list.eu/\\n\\nThe Tranco list is a research-oriented top sites ranking hardened against manipulation. It [combines\\nthe rankings of several source lists](https://tranco-list.eu/methodology) to produce a daily list\\nthat is based on data of the past 30 days.\\n\\nIYP uses this data to create and annotate DomainName nodes.\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"Virginia Tech\",\n",
      "            \"name\": \"RoVista\",\n",
      "            \"url\": \"https://rovista.netsecurelab.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/virginiatech#readme\",\n",
      "            \"reference_name\": \"virginiatech.rovista\",\n",
      "            \"readme_header\": \"# RoVista -- https://rovista.netsecurelab.org/\\n\\n> RoVista aims to determine the Routing Origin Validation (ROV) status of network\\n> operators.\\n>\\n> RoV Scores are determined based on the number of RPKI-invalid prefixes reachable by an\\n> Autonomous System (AS). Consequently, a higher ROV score suggests that the AS can\\n> effectively filter more RPKI-invalid prefixes. However, it is important to note that\\n> the RoV score does not conclusively indicate whether an AS has actually implemented\\n> ROV or not, partly due to limitations in [the] framework and other contributing\\n> factors.\\n\\nIYP converts these scores (or ratios) to two Tags:\\n\\n- ASes with a ratio greater than 0.5 are categorized as `Validating RPKI ROV`\\n- ASes with a ratio of less or equal 0.5 are categorized as `Not Validating RPKI ROV`\\n\"\n",
      "          },\n",
      "          {\n",
      "            \"organization\": \"World Bank\",\n",
      "            \"name\": \"Indicators API: Country Population Indicator\",\n",
      "            \"url\": \"https://www.worldbank.org\",\n",
      "            \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/worldbank#readme\",\n",
      "            \"reference_name\": \"worldbank.country_pop\",\n",
      "            \"readme_header\": \"# World Bank's country population -- https://www.worldbank.org/en/home\\n\\n> The World Bank Group works in every major area of development. We provide a wide array of financial products and technical assistance, and we help countries share and apply innovative knowledge and solutions to the challenges they face.\\n\\n> The World Bank is like a cooperative, made up of 189 member countries. These member countries, or shareholders, are represented by a Board of Governors, who are the ultimate policymakers at the World Bank. Generally, the governors are member countries' ministers of finance or ministers of development. They meet once a year at the Annual Meetings of the Boards of Governors of the World Bank Group and the International Monetary Fund.\\n\"\n",
      "          }\n",
      "        ]\n",
      "\n",
      "================================================================================\n",
      "Message 4\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🤔 THINKING\n",
      "      Content: We need dataset associated to IXPs. Likely PeeringDB ix, ixlan, fac, etc. Also CAIDA ix dataset. Provide modeling description: nodes types for IXP, Facility, LAN, Members etc, relationships. Need to fetch a resource to get readme details for PeeringDB or CAIDA. Let's get peeringdb.\n",
      "\n",
      "  [1] 🛠️ TOOL-CALL\n",
      "      Tool: get_resource\n",
      "      Tool Call ID: call_t66otkij\n",
      "      Args (JSON): {\"uri\":\"dataset://peeringdb.ix\"}\n",
      "\n",
      "================================================================================\n",
      "Message 5\n",
      "================================================================================\n",
      "📤 REQUEST\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 🔧 TOOL-RETURN\n",
      "      Tool: get_resource\n",
      "      Tool Call ID: call_t66otkij\n",
      "      Content: {\n",
      "          \"organization\": \"PeeringDB\",\n",
      "          \"name\": \"API endpoint: ix\",\n",
      "          \"url\": \"https://www.peeringdb.com\",\n",
      "          \"readme_url\": \"https://github.com/InternetHealthReport/internet-yellow-pages/tree/main/iyp/crawlers/peeringdb#readme\",\n",
      "          \"reference_name\": \"peeringdb.ix\",\n",
      "          \"readme_header\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\",\n",
      "          \"readme_content\": \"# PeeringDB crawlers -- https://www.peeringdb.com/\\n\\n[PeeringDB](https://www.peeringdb.com/) is a freely available, user-maintained, database of networks.\\nThe database contains information about Internet Exchange Points (IXPs) and data centers, including\\npeering LAN and membership information.\\n\\nIYP retrieves information about organizations, interconnection facilities, IXPs, their peering LANs,\\nand members.\\n\\n## Dependencies\\n\\nRun crawlers in this order:\\n\\n1. org\\n1. fac\\n1. ix\\n\\n## `org.py`\\n\\nInformation about organizations that own networks, IXPs, and facilities.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:Country {country_code})`: Country code\\n- `(:Name {name})`: Name\\n- `(:Organization {name})`: Name\\n- `(:PeeringdbOrgID {id})`: ID\\n- `(:URL {url})`: Website\\n\\nRelationships:\\n\\n```Cypher\\n(:Organization)-[:COUNTRY]->(:Country)\\n(:Organization)-[:EXTERNAL_ID]->(:PeeringdbOrgID)\\n(:Organization)-[:NAME]->(:Name)\\n(:Organization)-[:WEBSITE]->(:URL)\\n```\\n\\nThe `EXTERNAL_ID` relationship contains the raw organization data from PeeringDB [as defined in the\\nAPI.](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20org)\\n\\n## `fac.py`\\n\\nInformation about co-location facilities.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:Country {country_code})`: Country code\\n- `(:Facility {name})`: Name\\n- `(:Name {name})`: Name\\n- `(:PeeringdbFacID {id})`: ID\\n- `(:URL {url})`: Website\\n\\nRelationships:\\n\\n```Cypher\\n(:Facility)-[:COUNTRY]->(:Country)\\n(:Facility)-[:EXTERNAL_ID]->(:PeeringdbFacID)\\n(:Facility)-[:MANAGED_BY]->(:Organization)\\n(:Facility)-[:NAME]->(:Name)\\n(:Facility)-[:WEBSITE]->(:URL)\\n```\\n\\nThe `EXTERNAL_ID` relationship contains the raw facility data from PeeringDB [as defined in the\\nAPI.](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20fac)\\n\\n## `ix.py`\\n\\nInformation about IXPs, peering LANs, and IXP member networks.\\n\\n### Graph representation\\n\\nNodes:\\n\\n- `(:AS {asn})`: ASN of IXP member\\n- `(:IXP {name})`: Name\\n- `(:Name {name})`: Names of IXPs and networks\\n- `(:PeeringdbIXID {id})`: ID of the IXP\\n- `(:PeeringdbNetID {id})`: ID of the network\\n- `(:PeeringLAN {prefix})`: Prefix of IXP peering LAN\\n- `(:URL {url})`: Websites of IXPs and networks\\n\\nRelationships:\\n\\n```Cypher\\n(:IXP)-[:COUNTRY]->(:Country)\\n(:IXP)-[:EXTERNAL_ID]->(:PeeringdbIXID)\\n(:IXP)-[:LOCATED_IN]->(:Facility)\\n(:IXP)-[:MANAGED_BY]->(:Organization)\\n(:IXP)-[:NAME]->(:Name)\\n(:IXP)-[:WEBSITE]->(:URL)\\n\\n(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)\\n(:AS)-[:LOCATED_IN]->(:Facility)\\n(:AS)-[:MANAGED_BY]->(:Organization)\\n(:AS)-[:MEMBER_OF]->(:IXP)\\n(:AS)-[:NAME]->(:Name)\\n(:AS)-[:WEBSITE]->(:URL)\\n\\n(:PeeringLAN)-[:MANAGED_BY]->(:IXP)\\n```\\n\\nRaw data attached to relationships:\\n\\n- [`net`](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20net):\\n  - `(:AS)-[:EXTERNAL_ID]->(:PeeringdbNetID)`\\n  - `(:AS)-[:MANAGED_BY]->(:Organization)`\\n  - `(:AS)-[:MEMBER_OF]->(:IXP)`\\n  - `(:AS)-[:NAME]->(:Name)`\\n  - `(:AS)-[:WEBSITE]->(:URL)`\\n- [`netfac`](https://tutorial.peeringdb.com/apidocs/#tag/api/operation/list%20netfac):\\n  `(:AS)-[:LOCATED_IN]->(:Facility)`\\n\\n## Example\\n\\nRun the (long) query below to get an Example that contains all nodes and relationships created by\\nthe crawlers.\\n\\n```Cypher\\nMATCH (iij:AS {asn: 2497})-[r0:EXTERNAL_ID]->(n0:PeeringdbNetID)\\nMATCH (iij)-[r1:LOCATED_IN]->(n1:Facility {name: 'IIJ Ikebukuro DC'})\\nMATCH (iij)-[r2:MANAGED_BY]->(n2:Organization)\\nMATCH (iij)-[r3:MEMBER_OF]->(ix:IXP {name: 'DE-CIX Frankfurt'})\\nMATCH (iij)-[r4:NAME {reference_org: 'PeeringDB'}]->(n3:Name)\\nMATCH (iij)-[r5:WEBSITE]->(n4:URL)\\nMATCH (pfx:PeeringLAN {af: 4})-[r6:MANAGED_BY]->(ix)\\nMATCH (ix)-[r7:COUNTRY]->(n5:Country)\\nMATCH (ix)-[r8:EXTERNAL_ID]->(n6:PeeringdbIXID)\\nMATCH (ix)-[r9:LOCATED_IN]->(n7:Facility {name: 'Global Switch Frankfurt'})\\nMATCH (ix)-[r10:MANAGED_BY]->(n8:Organization)\\nMATCH (ix)-[r11:NAME]->(n9:Name)\\nMATCH (ix)-[r12:WEBSITE]->(n10)\\nRETURN iij,ix,pfx,n0,n1,n2,n3,n4,n5,n6,n7,n8,n9,n10,r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,r10,r11,r12\\n```\\n\\n![Nodes and relationships created by the PeeringDB\\ncrawler](/documentation/assets/gallery/peeringdbAll.svg)\\n\"\n",
      "        }\n",
      "\n",
      "================================================================================\n",
      "Message 6\n",
      "================================================================================\n",
      "📥 RESPONSE\n",
      "\n",
      "Parts:\n",
      "\n",
      "  [0] 💬 TEXT\n",
      "      Content: **IXPs in IYP – the dataset and the data model**\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣  Which dataset holds the IXP information?\n",
      "\n",
      "The Internet Yellow Pages (IYP) gets authoritative IXP data from **PeeringDB**.  \n",
      "The specific IYP dataset that you can query is:\n",
      "\n",
      "```\n",
      "dataset://peeringdb.ix\n",
      "```\n",
      "\n",
      "(You can also look at the related *fac* and *net* datasets for facilities and member networks.)\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣  How are IXPs modeled in the IYP knowledge‑graph?\n",
      "\n",
      "The PeeringDB crawler creates a rich graph that captures **IXPs, their f...\n"
     ]
    }
   ],
   "source": [
    "pretty_print_messages(result.all_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef66b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
